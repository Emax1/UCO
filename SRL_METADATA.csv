n;SI;title;author;journal;year;source;pages;volume;abstract;document_type;doi;url;affiliation;author_keywords;keywords;publisher;issn;language;note;selection_criteria
1;S;Stock trend forecasting in turbulent market periods using neuro-fuzzy systems;Atsalakis, George S. and Protopapadakis, Eftychios E. and Valavanis, Kimon P.;;;Springer Link;245--269;16;"This paper presents a neuro-fuzzy based methodology to forecast short-term stock trends during turbulent stock market periods. The methodology uses two adaptive neuro-fuzzy inference systems; the controller and the stock market process.The model is based on inverse control theory that simulates the stock market dynamics; enabling 1 day ahead forecasting. The proposed methodology is tested and evaluated using real stock shares data of the New York Stock Exchange.Data demonstrates transactions that occurred during four turbulent market periods: the Black Monday of October 19, 1987, the Russian crisis of 1998, the 11th of September 2001 crisis and the credit crisis of 2008.";;10.1007/s12351-015-0197-6;https://doi.org/10.1007/s12351-015-0197-6;;;;;1866-1505;;;
2;S;Impact of rail transit station proximity to commercial property prices: utilizing big data in urban real estate;Berawi, Mohammed Ali and Miraj, Perdana and Saroji, Gunawan and Sari, Mustika;;;Springer Link;71;7;Urban transport investments have contributed to the exponential increase of value from land and properties around the built infrastructure. Although literature had shown evidence of value uplift from the residential property due to transit development, little is known about the impact on commercial property values. This paper aims to evaluate the impact of rail transit proximity to the commercial property market by taking into account the pre-operation of the {LRT} project in Jakarta, Indonesia. This study utilizes a big data approach to accelerate research data processing by employing data mining method, as well as geographical information system ({GIS}) and hedonic price modeling ({HPM}) to investigate the property prices to formulate empirical evidence for the research. The results show opposite evidence compared to previous studies which argued that accessibility may contribute to the property price when closer to the transit station. The findings indicate that proximity to rail transit has an insignificant impact on the commercial property price compared to other variables such as building size, number of rooms, location, and hospitals. A comparison of the findings between this research with other studies was discussed and recommendation for further research development was proposed.;;10.1186/s40537-020-00348-z;https://doi.org/10.1186/s40537-020-00348-z;;;;;2196-1115;;;
3;S;Crossing the chasm: a ‘tube-map’ for agent-based social simulation of policy scenarios in spatially-distributed systems;Polhill, J. Gareth and Ge, Jiaqi and Hare, Matthew P. and Matthews, Keith B. and Gimona, Alessandro and Salt, Douglas and Yeluripati, Jagadeesh;;;Springer Link;169--199;23;"Agent based models ({ABMs}) simulate actions and interactions of autonomous agents/groups and their effect on systems as a whole, accounting for learning without assuming perfect rationality or complete knowledge. {ABMs} are an increasingly popular approach to studying complex, spatially distributed socio-environmental systems, but have still to become an established approach in the sense of being one that is expected by those wanting to explore scenarios in such systems. Partly, this is an issue of awareness – {ABM} is still new enough that many people have not heard of it; partly, it is an issue of confidence – {ABM} has more to do to prove itself if it is to become a preferred method. This paper will identify advances in the craft and deployment of {ABM} needed if {ABM} is to become an accepted part of mainstream science for policy or stakeholders. The conduct of {ABM} has, over the last decade, seen a transition from using abstracted representations of systems (supporting theory-led thought experiments) to more accessible representations derived empirically (to deliver more applied analysis). This has enhanced the perception of potential users of {ABM} outputs that the latter are salient and credible. Empirical {ABM} is not, however, a panacea, as it demands more computing and data resources, limiting applications to domains where data exist along with suitable environmental models where these are required. Further, empirical {ABM} is still facing serious questions of validation and the ontology used to describe the system in the first place. Using Geoffrey A. Moore’s Crossing the Chasm as a lens, we argue that the way ahead for {ABM} lies in identifying the niches in which it can best demonstrate its advantages, working with collaborators to demonstrate that it can deliver on its promises. This leads us to identify several areas where work is needed.";;10.1007/s10707-018-00340-z;https://doi.org/10.1007/s10707-018-00340-z;;;;;1573-7624;;;
4;S;Measuring objective and subjective well-being: dimensions and data sources;Voukelatou, Vasiliki and Gabrielli, Lorenzo and Miliou, Ioanna and Cresci, Stefano and Sharma, Rajesh and Tesconi, Maurizio and Pappalardo, Luca;;;Springer Link;279--309;11;Well-being is an important value for people’s lives, and it could be considered as an index of societal progress. Researchers have suggested two main approaches for the overall measurement of well-being, the objective and the subjective well-being. Both approaches, as well as their relevant dimensions, have been traditionally captured with surveys. During the last decades, new data sources have been suggested as an alternative or complement to traditional data. This paper aims to present the theoretical background of well-being, by distinguishing between objective and subjective approaches, their relevant dimensions, the new data sources used for their measurement and relevant studies. We also intend to shed light on still barely unexplored dimensions and data sources that could potentially contribute as a key for public policing and social development.;;10.1007/s41060-020-00224-2;https://doi.org/10.1007/s41060-020-00224-2;;;;;2364-4168;;;
5;S;Comparing {OLS} based hedonic model and {ANN} in house price estimation using relative location;Mankad, Mudit D.;;;Springer Link;;;Accurate house price estimation is of great importance not only to various real estates stakeholders such as house owners, buyers, investors, and agents but also to banking and insurance sectors among others. This estimation is a very challenging and complex task as it involves a variety of attributes. Among all attributes, location is one of the most influential attributes affecting house price. The present study has incorporated selected structural attributes and relative location through spatial attributes (geographical, infrastructural, and neighborhood) for modeling the influence of location on house prices. The hedonic model, a traditional method for estimating house price has been criticized due to nonlinearity, multicollinearity, and heteroskedasticity problems. Unlike the hedonic model, the Artificial Neural Network ({ANN}) permits nonlinear relationships and also tries to solve the problem of multicollinearity. The present study aims to examine the application of {ANN} in estimating accurate house prices and comparing the results with the Ordinary Least Squares ({OLS}) based hedonic model. The Gotri area located in the western part of Vadodara city, India is considered as a case study. {TensorFlow} (a python environment) of Google is used to implement the {ANN} model. In {ANN} model building, a three-layer network with a single hidden layer and {RELU} ({REctified} Linear Unit) activation function is adopted. The estimation performance has been evaluated by employing Root Mean Squared Error and Mean Absolute Percentage Error. According to results, {ANN} was found better when compared to {OLS} in terms of both the performance measures. This paper suggests that the {ANN} estimator could be a complement to the {OLS} based linear regression method.;;10.1007/s41324-021-00416-3;https://doi.org/10.1007/s41324-021-00416-3;;;;;2366-3294;;;
6;S;Extension of the {VIKOR} method for group decision making with extended hesitant fuzzy linguistic information;Ghadikolaei, Abdolhamid Safaei and Madhoushi, Mehrdad and Divsalar, Mehdi;;;Springer Link;3589--3602;30;Group decision-making approaches are very important due to the complexity and uncertainty of many real-world decision-making problems. Some of the decision-making problems are defined in qualitative frameworks. Extended hesitant fuzzy linguistic term set ({EHFLTS}) is proposed as a new and powerful tool for elicitation of hesitant qualitative information in group decision-making process. In this paper, we first introduced the comparison laws and a family of distance and similarity measures for extended hesitant fuzzy linguistic terms ({EHFLTs}) and {EHFLTSs}, respectively. Next, we developed the extended hesitant fuzzy linguistic ({EHFL})-{VIKOR} method as a qualitative multi-attributes group decision-making approach based on the {EHFLTS} distance measures to deal with the qualitative hesitancy in group decision making. Finally, we presented an application example about selection of suitable telecommunications service provider of small- and medium-sized enterprises to verify applicability and validation of proposed method in the process of qualitative group decision making.;;10.1007/s00521-017-2944-5;https://doi.org/10.1007/s00521-017-2944-5;;;;;1433-3058;;;
7;S;The random neural network in price predictions;Serrano, Will;;;Springer Link;;;"Everybody likes to make a good prediction, in particular, when some sort of personal investment is involved in terms of finance, energy or time. The difficulty is to make a prediction that optimises the reward obtained from the original contribution; this is even more important when investments are the core service offered by a business or pension fund. The complexity of finance is that the human predictor may have other interests or bias than the human investor, the trust between predictor and investor will never be completely established as the investor will never know if the predictor has generated, intentionally or unintentionally, the optimum possible reward. This article presents the random neural network ({RNN}) in a recurrent configuration for the 4th industrial revolution on a Fintech application; the {RNN} is proposed to make predictions on time series data, specifically, prices. The biological model inspired by the brain structure and neural interconnections make predictions entirely on previous data from the time series rather than predictions based on several uncorrelated inputs. The model is validated against the property, stock and Fintech market: (1) {UK} property prices, (2) stock market indice prices, (3) cryptocurrency prices. Experimental results show that the proposed method makes accurate predictions on different investment portfolios. The prediction accuracy of the proposed {RNN} model is compared against long short-term memory ({LSTM}) and linear regression ({LR}) models.";;10.1007/s00521-021-05903-0;https://doi.org/10.1007/s00521-021-05903-0;;;;;1433-3058;;;
8;S;Using exploratory regression to identify optimal driving factors for cellular automaton modeling of land use change;Feng, Yongjiu and Tong, Xiaohua;;;Springer Link;515;189;Defining transition rules is an important issue in cellular automaton ({CA})-based land use modeling because these models incorporate highly correlated driving factors. Multicollinearity among correlated driving factors may produce negative effects that must be eliminated from the modeling. Using exploratory regression under pre-defined criteria, we identified all possible combinations of factors from the candidate factors affecting land use change. Three combinations that incorporate five driving factors meeting pre-defined criteria were assessed. With the selected combinations of factors, three logistic regression-based {CA} models were built to simulate dynamic land use change in Shanghai, China, from 2000 to 2015. For comparative purposes, a {CA} model with all candidate factors was also applied to simulate the land use change. Simulations using three {CA} models with multicollinearity eliminated performed better (with accuracy improvements about 3.6\%) than the model incorporating all candidate factors. Our results showed that not all candidate factors are necessary for accurate {CA} modeling and the simulations were not sensitive to changes in statistically non-significant driving factors. We conclude that exploratory regression is an effective method to search for the optimal combinations of driving factors, leading to better land use change models that are devoid of multicollinearity. We suggest identification of dominant factors and elimination of multicollinearity before building land change models, making it possible to simulate more realistic outcomes.;;10.1007/s10661-017-6224-8;https://doi.org/10.1007/s10661-017-6224-8;;;;;1573-2959;;;
9;S;Calibrating nonparametric cellular automata with a generalized additive model to simulate dynamic urban growth;Feng, Yongjiu and Tong, Xiaohua;;;Springer Link;496;76;Understanding factors that drive urban growth is essential to cellular automata ({CA}) based urban modeling. Multicollinearity among correlated factors may cause negative effects when building {CA} transition rules, leading to a decrease in simulation accuracy. We use a nonparametric generalized additive model ({GAM}) to evaluate these relationships through flexible smooth functions to capture the dynamics of urban growth. A {GAM}-based {CA} (termed {GAM}-{CA}) model was then developed to simulate the rapid urban growth in Shanghai, China from 2000 to 2015. {GAM} highlights the significance of each candidate factor driving urban growth during the past 15 years. Compared to logistic regression, the {GAM}-{CA} transition rules fitted the observed data better and yielded improved overall accuracy and hence more realistic urban growth patterns. The new {CA} model has great potential for capturing key driving factors to simulate dynamic urban growth, and can predict future scenarios under various spatial constraints and conditions.;;10.1007/s12665-017-6828-x;https://doi.org/10.1007/s12665-017-6828-x;;;;;1866-6299;;;
10;S;A scientometric analysis of the housing affordability literature;Adabre, Michael Atafo and Chan, Albert P. C. and Darko, Amos;;;Springer Link;1501--1533;36;Interest in the global unaffordable housing crisis is evident in its burgeoning publications. However, systematic review of the literature is limited concerning data visualization and mapping of the knowledge structure and worldwide trend of publications on housing. This study seeks to fill this knowledge gap through a quantitative method—scientometric analysis. To this end, three networking tools—{CiteSpace}, {VOSviewer} and Gephi—were employed in analysing 11,981 bibliographic records retrieved from Scopus for two decades (1998–2017). The research findings are informative in identifying trends, linkages and gaps in the literature. Besides, they reveal collaboration pattern among countries, academic institutions and publication outlets of housing studies. These have practical implications for policymakers. The findings are indicative of pivotal areas of relatively low research outputs that can be the focus for further research. They are also important for efficient research and development policies for attaining the United Nations Sustainable Development Goals in housing.;;10.1007/s10901-021-09825-0;https://doi.org/10.1007/s10901-021-09825-0;;;;;1573-7772;;;
11;S;The canary in the city: indicator groups as predictors of local rent increases;Steentoft, Aike A. and Poorthuis, Ate and Lee, Bu-Sung and Schläpfer, Markus;;;Springer Link;21;7;As cities grow, certain neighborhoods experience a particularly high demand for housing, resulting in escalating rents. Despite far-reaching socioeconomic consequences, it remains difficult to predict when and where urban neighborhoods will face such changes. To tackle this challenge, we adapt the concept of ‘bioindicators’, borrowed from ecology, to the urban context. The objective is to use an ‘indicator group’ of people to assess the quality of a complex environment and its changes over time. Specifically, we analyze 92 million geolocated Twitter records across five {US} cities, allowing us to derive socio-economic user profiles based on individual movement patterns. As a proof-of-concept, we define users with a ‘high-income-profile’ as an indicator group and show that their visitation patterns are a suitable indicator for expected future rent increases in different neighborhoods. The concept of indicator groups highlights the potential of closely monitoring only a specific subset of the population, rather than the population as a whole. If the indicator group is defined appropriately for the phenomenon of interest, this approach can yield early predictions while simultaneously reducing the amount of data that needs to be collected and analyzed.;;10.1140/epjds/s13688-018-0151-y;https://doi.org/10.1140/epjds/s13688-018-0151-y;;;;;2193-1127;;;
12;S;City intelligence for enhancing urban performance value: a conceptual study on data decomposition in smart cities;Kourtit, Karima;;;Springer Link;191--222;5;The contemporary ‘digital age’ prompts the need for a re-assessment of urban planning principles and practices. Against the background of current data-rich urban planning, this study seeks to address the question whether an appropriate methodological underpinning can be provided for smart city governance based on a data-driven planning perspective. It posits that the current digital technology age has a drastic impact on city strategies and calls for a multi-faceted perspective on future urban development, termed here the ‘{XXQ}-principle’ (which seeks to attain the highest possible level of quality for urban life). Heterogeneity in urban objectives and data embodied in the {XXQ}-principle can be systematically addressed by a process of data decomposition (based on a ‘cascade principle’), so that first, higher-level urban policy domains are equipped with the necessary (‘big’) data provisions, followed by lower-ranking urban governance levels. The conceptual decomposition principle can then be translated into a comprehensive hierarchical model architecture for urban intelligence based on the ‘flying disc’ model, including key performance indicators ({KPIs}). This new model maps out the socio-economic arena of a complex urban system according to the above cascade system. The design of this urban system architecture and the complex mutual connections between its subsystems is based on the ‘blowing-up’ principle that originates from a methodological deconstruction-reconstruction paradigm in the social sciences. The paper advocates the systematic application of this principle to enhance the performance of smart cities, called the {XXQ} performance value. This study is not empirical, although it is inspired by a wealth of previous empirical research. It aims to advance conceptual and methodological thinking on principles of smart urban planning.;;10.1007/s41685-021-00193-9;https://doi.org/10.1007/s41685-021-00193-9;;;;;2509-7954;;;
13;S;A New Neural Network Classifier Based on Atanassov’s Intuitionistic Fuzzy Set Theory;Giveki, Davar and Rastegar, Homayoun and Karami, Maryam;;;Springer Link;170--182;27;This paper proposes a new framework for training radial basis function neural networks ({RBFNN}). Determination of the centers of the Gaussian functions in the hidden layer of {RBF} neural network highly affects the performance of the network. This paper presents a novel radial basis function using fuzzy C-means clustering algorithm based on Atanassov’s intuitionistic fuzzy set (A-{IFS}) theory. The A-{IFS} theory takes into account another uncertainty parameter which is the hesitation degree that arises while defining the membership function and therefore, the cluster centers converge to more desirable locations than the cluster centers obtained using traditional fuzzy C-means algorithm. Furthermore, we make use of a new objective function obtained by Atanassov’s intuitionistic fuzzy entropy. This objective function is incorporated in the traditional fuzzy C-means clustering algorithm to maximize the good points in the class. The proposed method is used to improve the functionality of the Optimum Steepest Descent ({OSD}) learning algorithm. Adjusting {RBF} units in the network with great accuracy will result in better performance in fewer train iterations, which is essential when fast retraining of the network is needed, especially in the real-time systems. We compare the proposed Atanassov’s intuitionistic radial basis function neural network (A-{IRBFNN}) with fuzzy C-mean radial basis function neural network ({FCMRBFNN}) while both methods use {OSD} learning algorithm. Furthermore, the proposed A-{IRBFNN} is compared with other powerful fuzzy-based radial basis function neural network. Experimental results on Proben1 dataset and demonstrate the superiority of the proposed A-{IRBFNN}.;;10.3103/S1060992X18030062;https://doi.org/10.3103/S1060992X18030062;;;;;1934-7898;;;
14;S;The potential of volunteered geographic information to investigate peri-urbanization in the conservation zone of Mexico City;Heider, Katharina and Lopez, Juan Miguel Rodriguez and Scheffran, Jürgen;;;Springer Link;219;190;Due to the availability of Web 2.0 technologies, volunteered geographic information ({VGI}) is on the rise. This new type of data is available on many topics and on different scales. Thus, it has become interesting for research. This article deals with the collective potential of {VGI} and remote sensing to detect peri-urbanization in the conservation zone of Mexico City. On the one hand, remote sensing identifies horizontal urban expansion, and on the other hand, {VGI} of ecological complaints provides data about informal settlements. This enables the combination of top-down approaches (remote sensing) and bottom-up approaches (ecological complaints). Within the analysis, we identify areas of high urbanization as well as complaint densities and bring them together in a multi-scale analysis using Geographic Information Systems ({GIS}). Furthermore, we investigate the influence of settlement patterns and main roads on the peri-urbanization process in Mexico City using {OpenStreetMap}. Peri-urbanization is detected especially in the transition zone between the urban and rural (conservation) area and near main roads as well as settlements.;;10.1007/s10661-018-6597-3;https://doi.org/10.1007/s10661-018-6597-3;;;;;1573-2959;;;
15;S;Appraisal Accuracy and Automated Valuation Models in Rural Areas;Bogin, Alexander N. and Shui, Jessica;;;Springer Link;40--52;60;Accurate and unbiased property value estimates are essential to credit risk management. Along with loan amount, they determine a mortgage’s loan-to-value ratio, which captures the degree of homeowner equity and is a key determinant of borrower credit risk. For home purchases, lenders generally require an independent appraisal, which, in addition to a home’s sales price, is used to calculate a value for the underlying collateral. A number of empirical studies have shown that property appraisals tend to be biased upwards, and over 90 percent of the time, either confirm or exceed the associated contract price. Our data suggest that appraisal bias is particularly pervasive in rural areas where over 25 percent of rural properties are appraised at more than five percent above contract price. Given this significant upward bias, we examine a host of alternate valuation techniques to more accurately estimate rural property values.;;10.1007/s11146-019-09712-0;https://doi.org/10.1007/s11146-019-09712-0;;;;;1573-045X;;;
16;S;Peer-Dependence Valuation Model for Real Estate Appraisal;Bin, Junchi and Gardiner, Bryan and Li, Eric and Liu, Zheng;;;Springer Link;2;3;Deep learning recently attracts considerable attention thanks to its powerful computational capacities in image processing and natural language processing. More and more real estate brokers provide online “Deep” expert systems to help clients with their inquiry of targeted properties before deciding on the transaction of properties. The real estate appraisal is one of the most significant concerns for the clients. In the appraisal process, the estimation of house price depends not only on its attributes but also their neighbors. The influence from neighbors is known as peer-dependence, which is not directly measurable. Thus, real estate appraisal can be improved if the valuation includes the peer-dependence measurement. In this paper, we propose a peer-dependence valuation model ({PDVM}), which is capable of converting the peer-dependence-based valuation problem into a sequence prediction problem. In the proposed model, we first develop a method, K-nearest similar house sampling ({KNSHS}), to generate sequences from the to-be-value house and nearby houses. Secondly, the bidirectional long short-term memory (B-{LSTM}) layers extract the features of sequences. Finally, the fully connected ({FC}) layer estimates the house price based on the features. The experimental results indicate that our model outperforms the other state-of-the-art machine learning models being used for real estate appraisal.;;10.1007/s41688-018-0027-0;https://doi.org/10.1007/s41688-018-0027-0;;;;;2510-1161;;;
17;S;A new causal discovery heuristic;Prestwich, S. D. and Tarim, S. A. and Ozkan, I.;;;Springer Link;245--259;82;Probabilistic methods for causal discovery are based on the detection of patterns of correlation between variables. They are based on statistical theory and have revolutionised the study of causality. However, when correlation itself is unreliable, so are probabilistic methods: unusual data can lead to spurious causal links, while nonmonotonic functional relationships between variables can prevent the detection of causal links. We describe a new heuristic method for inferring causality between two continuous variables, based on randomness and unimodality tests and making few assumptions about the data. We evaluate the method against probabilistic and additive noise algorithms on real and artificial datasets, and show that it performs competitively.;;10.1007/s10472-018-9575-0;https://doi.org/10.1007/s10472-018-9575-0;;;;;1573-7470;;;
18;S;Scene Classification Using Multi-Resolution {WAHOLB} Features and Neural Network Classifier;Montazer, Gholam Ali and Giveki, Davar;;;Springer Link;681--704;46;This article approaches scene classification problem by proposing an enhanced bag of features ({BoF}) model and a modified radial basis function neural network ({RBFNN}) classifier. The proposed {BoF} model integrates the image features extracted by histogram of oriented gradients, local binary pattern and wavelet coefficients. The extracted features are obtained in a hierarchical multi-resolution manner. The proposed approach is able to capture multi-level (the pixel-, patch-, and image-level) features. The histograms of features constructed by {BoF} model are then used for training a modified {RBFNN} classifier. As a modification, we propose using a new variant of particle swarm optimization, in which the parameters are updated adaptively, for determining the center of Gaussian functions in {RBFNN}. Experimental results demonstrate that our proposed approach significantly outperforms the state-of-the-art methods on scene classification of {OT}, {FP}, and {LSP} benchmark datasets.;;10.1007/s11063-017-9614-6;https://doi.org/10.1007/s11063-017-9614-6;;;;;1573-773X;;;
19;S;Bayesian Estimation of Economic Simulation Models Using Neural Networks;Platt, Donovan;;;Springer Link;;;Recent advances in computing power and the potential to make more realistic assumptions due to increased flexibility have led to the increased prevalence of simulation models in economics. While models of this class, and particularly agent-based models, are able to replicate a number of empirically-observed stylised facts not easily recovered by more traditional alternatives, such models remain notoriously difficult to estimate due to their lack of tractable likelihood functions. While the estimation literature continues to grow, existing attempts have approached the problem primarily from a frequentist perspective, with the Bayesian estimation literature remaining comparatively less developed. For this reason, we introduce a widely-applicable Bayesian estimation protocol that makes use of deep neural networks to construct an approximation to the likelihood, which we then benchmark against a prominent alternative from the existing literature. Overall, we find that our proposed methodology consistently results in more accurate estimates in a variety of settings, including the estimation of financial heterogeneous agent models and the identification of changes in dynamics occurring in models incorporating structural breaks.;;10.1007/s10614-021-10095-9;https://doi.org/10.1007/s10614-021-10095-9;;;;;1572-9974;;;
20;S;Boosting house price predictions using geo-spatial network embedding;Das, Sarkar Snigdha Sarathi and Ali, Mohammed Eunus and Li, Yuan-Fang and Kang, Yong-Bin and Sellis, Timos;;;Springer Link;2221--2250;35;Real estate contributes significantly to all major economies around the world. In particular, house prices have a direct impact on stakeholders, ranging from house buyers to financing companies. Thus, a plethora of techniques have been developed for real estate price prediction. Most of the existing techniques rely on different house features to build a variety of prediction models to predict house prices. Perceiving the effect of spatial dependence on house prices, some later works focused on introducing spatial regression models for improving prediction performance. However, they fail to take into account the geo-spatial context of the neighborhood amenities such as how close a house is to a train station, or a highly-ranked school, or a shopping center. Such contextual information may play a vital role in users’ interests in a house and thereby has a direct influence on its price. In this paper, we propose to leverage the concept of graph neural networks to capture the geo-spatial context of the neighborhood of a house. In particular, we present a novel method, the geo-spatial network embedding ({GSNE}), that learns the embeddings of houses and various types of points of interest ({POIs}) in the form of multipartite networks, where the houses and the {POIs} are represented as attributed nodes and the relationships between them as edges. Extensive experiments with a large number of regression techniques show that the embeddings produced by our proposed {GSNE} technique consistently and significantly improve the performance of the house price prediction task regardless of the downstream regression model. Relevant source code for {GSNE} is available at: https://github.com/sarathismg/gsne.;;10.1007/s10618-021-00789-x;https://doi.org/10.1007/s10618-021-00789-x;;;;;1573-756X;;;
21;S;On the Directional Accuracy of United States Housing Starts Forecasts: Evidence from Survey Data;Meyer, Tim;;;Springer Link;457--488;58;I use data from both the Survey of Professional Forecasters and the Livingston Survey to study the directional accuracy of United States housing starts forecasts. Using elements of relative operating characteristic ({ROC}) analysis, I find that forecasts contain information with respect to subsequent changes in housing starts. Estimates for both surveys are significant at all forecast horizons and robust across time and across forecasters. Implications for the usage of housing starts forecasts from survey data are discussed.;;10.1007/s11146-017-9637-9;https://doi.org/10.1007/s11146-017-9637-9;;;;;1573-045X;;;
22;S;Automated valuation model for residential rental markets: evidence from Japan;Cheung, William and Guo, Lewen and Kawaguchi, Yuichiro;;;Springer Link;2;2;We introduce a new type of automated valuation model ({AVM}) for residential rental markets employing the ordinary kriging method. Using nearly 300, 000 coordinates of individual properties and a proprietary dataset of asking rental prices, we form a unique micro-level housing rental dataset for five major metropolitan areas in Tokyo, Japan, and estimate the rental {AVM} with kriging, utilising only latitude and longitude. From our training and test datasets, we find that the accuracy of the ordinary kriging method is comparable to the traditional hedonic pricing approach, which requires substantial property information. Our finding suggests that the efficiency of the ordinary kriging approach for rental {AVM} is comparable to the hedonic pricing approach. For robustness, we investigate the roles of spatial variables based on our baseline hedonic regression models. Spatial variables—latitudes, longitudes, and distance to Tokyo Station—are significant in determining housing rents in the Tokyo residential market. By providing an open-source {AVM} for the residential rental market, we alleviate the information asymmetry between the tenants-to-be and property owners and increase the efficiency of housing markets.;;10.1007/s43071-021-00009-0;https://doi.org/10.1007/s43071-021-00009-0;;;;;2662-298X;;;
23;S;Reliable region predictions for automated valuation models;Bellotti, Anthony;;;Springer Link;71--84;81;Accurate property valuation is important for property purchasers, investors and for mortgage-providers to assess credit risk in the mortgage market. Automated valuation models ({AVM}) are being developed to provide cheap, objective valuations that allow dynamic updating of property values over the term of a mortgage. A useful feature of automated valuations is to provide a region of plausible price estimates for each individual property, rather than just a single point estimate. This would allow buyers and sellers to understand uncertainty on pricing individual properties and mortgage providers to include conservatism in their credit risk assessment. In this study, Conformal Predictors ({CP}) are used to provide such region predictions, whilst strictly controlling for predictive accuracy. We show how an {AVM} can be constructed using a {CP}, based on an underlying k-nearest neighbours approach. Time trend in property prices is dealt with by assuming a systematic effect over time and adjusting prices in the training data accordingly. The {AVM} is tested on a large data set of London property prices. Region predictions are shown to be reliable and the efficiency, ie region width, of property price predictions is investigated. In particular, a regression model is constructed to model the uncertainty in price prediction linked to property characteristics.;;10.1007/s10472-016-9534-6;https://doi.org/10.1007/s10472-016-9534-6;;;;;1573-7470;;;
24;S;Learning with self-attention for rental market spatial dynamics in the Atlanta metropolitan area;Zhou, Xiaolu and Tong, Weitian;;;Springer Link;837--845;14;The rental housing market plays a critical role in the United States real estate market. Prior studies have used various approaches to model housing rent, such as interpolation, hedonic modeling, and machine learning. However, only a few studies have modeled rental prices based on textual data, which provides rich and contextual information about rental properties. In addition, many models, especially deep learning models, use an end-to-end black box for prediction, which hides the decision process. Such models are difficult to interpret and explain the driving factors. This study builds on our previous work, aiming to develop and evaluate rental market spatial dynamics models combining Long Short-Term Memory ({LSTM}) networks and self-attention mechanism. We compare the performance of the proposed model with our previous models on predicting rental prices in Atlanta, Georgia, {USA}. We also use techniques from saliency maps to explain the generated model. Results show that the self-attention-based model outperforms our previous models. The saliency map techniques reveal how the model attends to a different part of the textual information. The predicted results reflect the spatial variation of textual information. Such a model offers practical pricing references for homeowners and renters, and spatial patterns for urban planners and stakeholders.;;10.1007/s12145-021-00589-3;https://doi.org/10.1007/s12145-021-00589-3;;;;;1865-0481;;;
25;S;Reverse mortgages through artificial intelligence: new opportunities for the actuaries;di Lorenzo, Emilia and Piscopo, Gabriella and Sibillo, Marilena and Tizzano, Roberto;;;Springer Link;23--35;44;"In its basic structure, the reverse mortgage ({RM}) is a contract where a home owner borrows a part or the totality of the future liquidation value of his home at the time of his death. The risks that are borne by the lender are linked to the volatility of the real estate market, that is the house price risk, the financial market risk, that is the interest rate risk, and the uncertainty of the borrower’s lifetime, that is the longevity risk. The quantification of the future liquidation value and its valuation at the issue time is fundamental in the construction of the {RM} contract either in the perspective of the lender or in the one of the borrower. In the paper, we explore the use of neural networks to project the real estate market data; this approach allows to obtain a predictive analysis of the pricing process and indeed provides a dynamic pricing algorithm.";;10.1007/s10203-020-00274-y;https://doi.org/10.1007/s10203-020-00274-y;;;;;1129-6569;;;
26;S;Customer demand analysis of the electronic commerce supply chain using Big Data;Li, Lei and Chi, Ting and Hao, Tongtong and Yu, Tao;;;Springer Link;113--128;268;"With the advent of the Internet and the flourishing of connected technology, electronic commerce has become a new business model that disrupts the traditional transactional model and is transforming the consumer’s lifestyle. Electronic commerce leads to constantly changing customer needs, therefore quick action and collaboration between production and the market is essential. Meanwhile, the abundant transactional data generated by electronic commerce allows us to explore browsing behaviors, habits, preferences and even characteristics of customers, which can help companies to understand their customer’s needs more clearly. Traditional supply chain management ({SCM}) simply cannot keep up with electronic commerce because demand forecasts are constantly changing. Customer demands create and affect the whole supply chain. The purpose of {SCM} is to satisfy the customers who support the company by paying for the products; so meeting changing customer needs should be incorporated into {SCM} by developing demand chain management ({DCM}). In this paper, we explore how {DCM} can perform better in the electronic commerce environment based on studying website behavior data and using data analytics tools. The results show that {DCM} performs much better when paired with the benefits of electronic commerce and Big Data than traditional {SCM} methods.";;10.1007/s10479-016-2342-x;https://doi.org/10.1007/s10479-016-2342-x;;;;;1572-9338;;;
27;S;A meso-level empirical validation approach for agent-based computational economic models drawing on micro-data: a use case with a mobility mode-choice model;Bektas, Alperen and Piana, Valentino and Schumann, René;;;Springer Link;80;1;The complex nature of agent-based modeling may reveal more descriptive accuracy than analytical tractability. That leads to an additional layer of methodological issues regarding empirical validation, which is an ongoing challenge. This paper offers a replicable method to empirically validate agent-based models, a specific indicator of “goodness-of-validation” and its statistical distribution, leading to a statistical test in some way comparable to the p value. The method involves an unsupervised machine learning algorithm hinging on cluster analysis. It clusters the ex-post behavior of real and artificial individuals to create meso-level behavioral patterns. By comparing the balanced composition of real and artificial agents among clusters, it produces a validation score in [0, 1] which can be judged thanks to its statistical distribution. In synthesis, it is argued that an agent-based model can be initialized at the micro-level, calibrated at the macro-level, and validated at the meso-level with the same data set. As a case study, we build and use a mobility mode-choice model by configuring an agent-based simulation platform called {BedDeM}. We cluster the choice behavior of real and artificial individuals with the same ex-ante given characteristics. We analyze these clusters’ similarity to understand whether the model-generated data contain observationally equivalent behavioral patterns as the real data. The model is validated with a specific score of 0.27, which is better than about 95\% of all possible scores that the indicator can produce. By drawing lessons from this example, we provide advice for researchers to validate their models if they have access to micro-data.;;10.1007/s43546-021-00083-4;https://doi.org/10.1007/s43546-021-00083-4;;;;;2662-9399;;;
28;S;Methods for Small Area Population Forecasts: State-of-the-Art and Research Needs;Wilson, Tom and Grossman, Irina and Alexander, Monica and Rees, Phil and Temple, Jeromey;;;Springer Link;;;Small area population forecasts are widely used by government and business for a variety of planning, research and policy purposes, and often influence major investment decisions. Yet, the toolbox of small area population forecasting methods and techniques is modest relative to that for national and large subnational regional forecasting. In this paper, we assess the current state of small area population forecasting, and suggest areas for further research. The paper provides a review of the literature on small area population forecasting methods published over the period 2001–2020. The key themes covered by the review are extrapolative and comparative methods, simplified cohort-component methods, model averaging and combining, incorporating socioeconomic variables and spatial relationships, ‘downscaling’ and disaggregation approaches, linking population with housing, estimating and projecting small area component input data, microsimulation, machine learning, and forecast uncertainty. Several avenues for further research are then suggested, including more work on model averaging and combining, developing new forecasting methods for situations which current models cannot handle, quantifying uncertainty, exploring methodologies such as machine learning and spatial statistics, creating user-friendly tools for practitioners, and understanding more about how forecasts are used.;;10.1007/s11113-021-09671-6;https://doi.org/10.1007/s11113-021-09671-6;;;;;1573-7829;;;
29;S;Identifying the effect of retail brands on private residential rental prices in Great Britain;Clark, Stephen and Hood, Nick and Birkin, Mark;;;Springer Link;;;This study extends our understanding of the influence of proximity to retail grocery provision on housing rental prices. To achieve this, extensive data on the size and location of retail outlets are combined with neighbourhood rental values for small areas across a two year period, together with varied contextual data for each area. In order to control the influence of many confounding variables in the determination of housing rentals, the technique of propensity score matching is applied. This provides a sophisticated means for the comparison between areas where there is substantial natural variation, rather than manageable controls. For a variety of types of retail brands, only a significant relationship is found between the proximity of a Premium retail outlet and the housing rental value. The findings of this research allow local planning officers to further understand the impact of planning applications on the potential for gentrification and the affordability of neighbouring housing.;;10.1007/s10901-021-09904-2;https://doi.org/10.1007/s10901-021-09904-2;;;;;1573-7772;;;
30;S;Drawing on different disciplines: macroeconomic agent-based models;Haldane, Andrew G. and Turrell, Arthur E.;;;Springer Link;39--66;29;Macroeconomic modelling has been under intense scrutiny since the Great Financial Crisis, when serious shortcomings were exposed in the methodology used to understand the economy as a whole. Criticism has been levelled at the assumptions employed in the dominant models, particularly that economic agents are homogenous and optimising and that the economy is equilibrating. In a related paper (Haldane and Turrell Oxford Rev Econ Polic 34(1–2):219–251 2018), we argue that an interdisciplinary approach to modelling in macroeconomics is beneficial. Here we focus on what one such approach - agent-based modelling, which has been extensively used across a wide range of disciplines - could do for macroeconomics. Agent-based models are complementary to existing approaches to macroeconomics and are particularly well-suited to answering questions where complexity, heterogeneity, networks, and heuristics play an important role.;;10.1007/s00191-018-0557-5;https://doi.org/10.1007/s00191-018-0557-5;;;;;1432-1386;;;
31;S;Automatic calibration of dynamic and heterogeneous parameters in agent-based models;Kim, Dongjun and Yun, Tae-Sub and Moon, Il-Chul and Bae, Jang Won;;;Springer Link;46;35;"Simulation has been applied to diverse domains such as urban growth modeling and market dynamics modeling. Some of these applications may require validations, based on some real-world observations modeled in the simulation. This validation can be conducted as either qualitative face-validation or quantitative empirical validation; however, as the importance and accumulation of data grows, the importance of quantitative validation has been highlighted in recent studies. The key component of quantitative validation is finding a calibrated set of parameters to regenerate the real-world observations in the simulation models. While the parameter of interest to be calibrated has hitherto been fixed throughout simulation executions, we expand the static parameter calibration in two dimensions in this study, dynamically and heterogeneously. The dynamic calibration changes the parameter values over the simulation period by reflecting the simulation output trend, and the heterogeneous calibration changes the parameter values per simulated entity clusters by considering the similarities of the entity states. We experimented with the proposed calibrations on a hypothetical case and a real-world case. For the hypothetical scenario, we used the wealth distribution model to illustrate how our calibration works. For the real-world scenario, we selected the real estate market model. The models were selected, because of two reasons. First, they have heterogeneous entities, being agent-based models. Second, they are agent-based models exhibiting real-world trends over time.";;10.1007/s10458-021-09528-4;https://doi.org/10.1007/s10458-021-09528-4;;;;;1573-7454;;;
32;S;Foreclosures and House Prices;Loberto, Michele;;;Springer Link;;;This paper studies the impact of foreclosures on house prices in Italy using a large dataset of online listings provided by Immobiliare.it, the most popular online portal for real estate services in Italy. We estimate that the foreclosure discount is considerable, and this would suggest a high degree of market segmentation and limited spillovers from foreclosures to the market for non-foreclosed homes. However, by exploiting the exogeneity of the market entry of foreclosures, we find that new foreclosures increase home sellers’ propensity to adjust their list price. Moreover, following the methodology in Campbell et al. (Am Econ Rev 101(5):2108–2131, 2011), we show that foreclosure listings have a significant negative impact on the prices of non-foreclosed nearby homes. Our evidence is quantitatively consistent with the recent literature on the impact of foreclosures on the {US} housing market.;;10.1007/s40797-021-00166-z;https://doi.org/10.1007/s40797-021-00166-z;;;;;2199-3238;;;
33;S;Boosted Tree Ensembles for Artificial Intelligence Based Automated Valuation Models ({AI}-{AVM});Sing, Tien Foo and Yang, Jesse Jingye and Yu, Shi Ming;;;Springer Link;;;This paper develops an artificial intelligence based automated valuation model ({AI}-{AVM}) using the boosting tree ensemble technique to predict housing prices in Singapore. We use more than 300,000 private and public housing transactions in Singapore for the period from 1995 to 2017 in the training of the {AI}-{AVM} models. The boosting model is the best predictive model that produce the most robust and accurate predictions for housing prices compared to the decision tree and multiple regression analysis ({MRA}) models. The boosting {AI}-{AVM} models explain 91.33\% and 94.28\% of the price variances, and keep the mean absolute percentage errors at 8.55\% and 5.34\% for the public housing market and the private housing market, respectively. When subject the {AI}-{AVM} to the out-of-sample forecasting using the 2018 housing sale samples, the prediction errors remain within a narrow range of between 5\% and 9\%.;;10.1007/s11146-021-09861-1;https://doi.org/10.1007/s11146-021-09861-1;;;;;1573-045X;;;
34;S;Forecasting Inflection Points: Hybrid Methods with Multiscale Machine Learning Algorithms;Chevallier, Julien and Zhu, Bangzhu and Zhang, Lyuyuan;;;Springer Link;537--575;57;This paper investigates hybrid time series forecasting models, which are based on combinations of ensemble empirical mode decomposition and least squares support vector machines. Several algorithms are considered: the genetic algorithm, the grid search, and particle swarm optimization. Theoretical guarantees of prediction accuracy are tested with sine curves. From a numerical testing perspective, we are interested in showing the superiority of one approach to another based on theoretical prediction and time series applications in finance (S\&P 500), commodities ({WTI} oil price), or cryptocurrencies (Bitcoin). The superiority of hybrid models to soft- and hard-computed models is further assessed through a ‘horse race’ and trading performance, as well as through fine-tuning of the algorithms.;;10.1007/s10614-019-09966-z;https://doi.org/10.1007/s10614-019-09966-z;;;;;1572-9974;;;
35;S;A mass-market appraisal of the English housing rental market using a diverse range of modelling techniques;Clark, Stephen D. and Lomax, Nik;;;Springer Link;43;5;Mass appraisals in the rental housing market are far less common than those in the sales market. However, there is evidence for substantial growth in the rental market and this lack of insight hampers commercial organisations and local and national governments in understanding this market.;;10.1186/s40537-018-0154-3;https://doi.org/10.1186/s40537-018-0154-3;;;;;2196-1115;;;
36;S;{COVID}-19’s impact on real estate markets: review and outlook;Balemi, Nadia and Füss, Roland and Weigand, Alois;;;Springer Link;495--513;35;As symbolized by vacant office buildings, empty shopping malls and abandoned flats in metropolitan areas, the new coronavirus disease 2019 has severely impacted real estate markets. This paper provides a comprehensive literature review of the latest academic insights into how this pandemic has affected the housing, commercial real estate and the mortgage market. Moreover, these findings are linked to comprehensive statistics of each real estate sector’s performance during the crisis. Finally, the paper includes an outlook and discusses possible future developments in each real estate segment.;;10.1007/s11408-021-00384-6;https://doi.org/10.1007/s11408-021-00384-6;;;;;2373-8529;;;
37;S;Tilted platforms: rental housing technology and the rise of urban big data oligopolies;Boeing, Geoff and Besbris, Max and Wachsmuth, David and Wegmann, Jake;;;Springer Link;6;3;This article interprets emerging scholarship on rental housing platforms—particularly the most well-known and used short- and long-term rental housing platforms—and considers how the technological processes connecting both short-term and long-term rentals to the platform economy are transforming cities. It discusses potential policy approaches to more equitably distribute benefits and mitigate harms. We argue that information technology is not value-neutral. While rental housing platforms may empower data analysts and certain market participants, the same cannot be said for all users or society at large. First, user-generated online data frequently reproduce the systematic biases found in traditional sources of housing information. Evidence is growing that the information broadcasting potential of rental housing platforms may increase rather than mitigate sociospatial inequality. Second, technology platforms curate and shape information according to their creators’ own financial and political interests. The question of which data—and people—are hidden or marginalized on these platforms is just as important as the question of which data are available. Finally, important differences in benefits and drawbacks exist between short-term and long-term rental housing platforms, but are underexplored in the literature: this article unpacks these differences and proposes policy recommendations.;;10.1186/s42854-021-00024-2;https://doi.org/10.1186/s42854-021-00024-2;;;;;2524-8162;;;
38;S;Predicting housing price in China based on long short-term memory incorporating modified genetic algorithm;Liu, Rui and Liu, Lu;;;Springer Link;11829--11838;23;Predicting the future trend and fluctuation of housing price is an important research problem of housing market. The machine learning approach is rarely used in existing studies, while the traditional prediction models have strict requirements on input variables and are weak in solving nonlinear problem. To overcome the problems of traditional models, a long short-term memory ({LSTM}) approach is proposed to predict the housing price of a city by using historical data. The proposed {LSTM} incorporates a modified genetic algorithm with multi-level probability crossover to select appropriate features and the optimal hyper-parameters. The data of housing price and related features of Shenzhen, China, from year 2010 to 2017 have been used to test the performance of the model. The results indicate that the proposed method has good performance in modeling housing price and is obviously outperforms other algorithms including back propagation neural network, support vector regression and different evolution {LTSM}. Therefore, this proposed model can be used efficiently for predicting housing price and thus can be a good tool for policy makers and investors to monitor the housing market.;;10.1007/s00500-018-03739-w;https://doi.org/10.1007/s00500-018-03739-w;;;;;1433-7479;;;
39;S;Housing price variations using spatio-temporal data mining techniques;Soltani, Ali and Pettit, Christopher James and Heydari, Mohammad and Aghaei, Fatemeh;;;Springer Link;1199--1227;36;"The issue of property evaluation and appraisal has been of high interest for private and public agents involved in the housing industry for the purposes of trade, insurance and tax. This paper aims to investigate how different factors related to the location of a property affect its price over time. The predictive models applied in this research are driven by real estate transactions data of Tehran Metropolitan Area, captured from open data available to the public. The parameters of the functions that describe the behavior of the housing market are estimated through applying different types of statistical models, including ordinary least squares ({OLS}), geographically weighted regression ({GWR}) and geographically and temporally weighted regression ({GTWR}). This suite of models has been run in order to compare their efficiency and accuracy in predicting the variations in housing price. The {GTWR} model showed significantly better performance than {OLS} and {GWR} models, as the goodness of fit index (adjusted R2) improved by 22 percent. Therefore, spatio-temporal non-stationary modelling is significant in the explanation of the variations in housing value and the {GTWR} coefficients were found more reliable. Three internal factors (size of building; building age; building quality), and eight external factors (topography; land-use mix; population density; distance to city center; distance to subway station; distance to regional parks; distance to highway; distance to airport) influence the property price, either positively or negatively. Moreover, using significant variables that extracted from regression models, the optimum number of housing value clusters is generated using the spatial ‘k’luster analysis by tree edge removal ({SKATER}) method. Five clusters of housing patterns were recognized. The policy implication of this paper is grouping of Metropolitan Tehran housing value data into five clusters with different characteristics. The varying factors influencing housing value in each cluster are different, making this data analysis technique useful for policy-makers in the housing sector.";;10.1007/s10901-020-09811-y;https://doi.org/10.1007/s10901-020-09811-y;;;;;1573-7772;;;
40;S;The impact of social influence in Australian real estate: market forecasting with a spatial agent-based model;Evans, Benjamin Patrick and Glavatskiy, Kirill and Harré, Michael S. and Prokopenko, Mikhail;;;Springer Link;;;Housing markets are inherently spatial, yet many existing models fail to capture this spatial dimension. Here, we introduce a new graph-based approach for incorporating a spatial component in a large-scale urban housing agent-based model ({ABM}). The model explicitly captures several social and economic factors that influence the agents’ decision-making behaviour (such as fear of missing out, their trend-following aptitude, and the strength of their submarket outreach), and interprets these factors in spatial terms. The proposed model is calibrated and validated with the housing market data for the Greater Sydney region. The {ABM} simulation results not only include predictions for the overall market, but also produce area-specific forecasting at the level of local government areas within Sydney as arising from individual buy and sell decisions. In addition, the simulation results elucidate agent preferences in submarkets, highlighting differences in agent behaviour, for example, between first-time home buyers and investors, and between both local and overseas investors.;;10.1007/s11403-021-00324-7;https://doi.org/10.1007/s11403-021-00324-7;;;;;1860-7128;;;
41;S;Real estate price estimation in French cities using geocoding and machine learning;Tchuente, Dieudonné and Nyawa, Serge;;;Springer Link;;;This paper reviews real estate price estimation in France, a market that has received little attention. We compare seven popular machine learning techniques by proposing a different approach that quantifies the relevance of location features in real estate price estimation with high and fine levels of granularity. We take advantage of a newly available open dataset provided by the French government that contains 5 years of historical data of real estate transactions. At a high level of granularity, we obtain important differences regarding the models’ prediction powers between cities with medium and high standards of living (precision differences beyond 70\% in some cases). At a low level of granularity, we use geocoding to add precise geographical location features to the machine learning algorithm inputs. We obtain important improvements regarding the models’ forecasting powers relative to models trained without these features (improvements beyond 50\% for some forecasting error measures). Our results also reveal that neural networks and random forest techniques particularly outperform other methods when geocoding features are not accounted for, while random forest, adaboost and gradient boosting perform well when geocoding features are considered. For identifying opportunities in the real estate market through real estate price prediction, our results can be of particular interest. They can also serve as a basis for price assessment in revenue management for durable and non-replenishable products such as real estate.;;10.1007/s10479-021-03932-5;https://doi.org/10.1007/s10479-021-03932-5;;;;;1572-9338;;;
42;S;A New Appraisal Model of Second-Hand Housing Prices in China’s First-Tier Cities Based on Machine Learning Algorithms;Xu, Lulin and Li, Zhongwu;;;Springer Link;617--637;57;The accurate appraisal of second-hand housing prices plays an important role in second-hand housing transactions, mortgages and risk assessment. Machine learning technology, gradually applied to finance and economics, can also be used to upgrade the traditional appraisal methods of second-hand housing. A large number of appraisal indicators and price data on second-hand housing in Beijing, Shanghai, Guangzhou and Shenzhen, four first-tier cities in China, can be obtained by using crawler technology. Then, the geographical location information of second-hand housing can be visualized by {GIS} technology, and the descriptive text of second-hand housing can be processed by natural language processing. Finally, combined with other numerical and classification indicators, the second-hand housing appraisal model based on a two-tier stacking framework is constructed by using random forest, adaptive boosting, gradient boosting decision tree, light gradient boosting machine and extreme gradient boosting as base models and back propagation neural network as the meta-model. The result of model training shows that the machine learning models improve the accuracy significantly compared to linear multiple regression and spatial econometric models, and the performance of the stacking model is better than that of standalone machine learning models.;;10.1007/s10614-020-09973-5;https://doi.org/10.1007/s10614-020-09973-5;;;;;1572-9974;;;
43;S;Combining Property Price Predictions from Repeat Sales and Spatially Enhanced Hedonic Regressions;Oust, Are and Hansen, Simen N. and Pettrem, Tobias R.;;;Springer Link;183--207;61;Hedonic regression and repeat sales are commonly used methods in real estate analysis. While the merits of combining these models when constructing house price indices are well documented, research on the utility of adopting the same approach for residential property valuation has not been conducted to date. Specifically, house value estimates were obtained by combining predictions from repeat sales and various hedonic regression specifications, which were enhanced to account for spatial effects. Three of these enhancements—regression kriging, mixed regressive-spatial autoregressive, and geographically weighted regression—are widely utilized spatial econometric models. However, a fourth augmentation, which addresses systematic residual patterns in regressions with district indicator variables and the presence of outliers in housing data, was also proposed. The resulting models were applied to a dataset containing 16,417 real estate transactions in Oslo, Norway, revealing that when the repeat sales approach is included, it reduces the median absolute percentage error of solely hedonic models by 6.8–9.5\%, where greater improvements are associated with less accurate spatial enhancements. These improvements can be attributed to the inclusion of both spatial and non-spatial information inherent in previous sales prices. While the former has limited utility for well-specified spatial models, the non-spatial information that is implicit in previous sales prices likely captures otherwise difficult to observe phenomena, potentially making its contribution highly valuable in automated valuation models.;;10.1007/s11146-019-09723-x;https://doi.org/10.1007/s11146-019-09723-x;;;;;1573-045X;;;
44;S;Recent trends in real estate research: a comparison of recent working papers and publications using machine learning algorithms;Breuer, Wolfgang and Steininger, Bertram I.;;;Springer Link;963--974;90;sinr;;10.1007/s11573-020-01005-w;https://doi.org/10.1007/s11573-020-01005-w;;;;;1861-8928;;;
45;S;Predicting fair housing market value: A machine learning investigation;Oladunni, T. and Sharma, S.;International Journal of Computers and their Applications;2016;Scopus;160-175;23;"The real estate market plays a major role in the economy of most developed nations, particularly the United States, thus a study of its market value prediction using machine learning algorithms is very important. This paper describes a two phase research into the predictability of the fair market value of real estate properties. The first phase concentrated on building a predictive real estate listings application software using an MVC architecture and linear regression. Residential real estate datasets extracted from Howard County, Maryland were used for the experiment. Performance evaluation was measured using r-squared with a performance outcome of 0.92. The second phase of the study experimented the model with four different learning algorithms; K-NN, improved neural network, polynomial regression and linear regression. Experiments were conducted with datasets of residential real estate listings from Baltimore and Montgomery counties. Spearman’s rho was used for the performance comparisons of the algorithms. Neural network performed consistently better in both counties with a Spearman’s rho value of 0.836 and 0.739 in Montgomery County and Baltimore County respectively. Statistical analysis was done using scatter plot, covariance matrix, correlation matrix and test of significance. Statistical analysis showed that the predictive parameters of real estate properties are not the same in all counties. © ISCA 2016.";Article;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096893915&partnerID=40&md5=3f5e140a240429997be04f5432fc407d;Department of Computer Science, Bowie State University, Bowie, MD  20715, United States;"Housing prices prediction;  K-NN;  Linear regression;  Machine learning;  MVC;  Neural network;  Polynomial regression;  Real estate;  UML";;;;;cited By 0;
46;S;Forecasting spatial dynamics of the housing market using Support Vector Machine;Chen, J.-H. and Ong, C.F. and Zheng, L. and Hsu, S.-C.;International Journal of Strategic Property Management;2017;Scopus;273-283;21;"This paper adopts a novel approach of Support Vector Machine (SVM) to forecast residential housing prices. as one type of machine learning algorithm, the proposed SVM encompasses a larger set of variables that are recognized as price-influencing and meanwhile enables recognizing the geographical pattern of housing price dynamics. The analytical framework consists of two steps. The first step is to identify the supporting vectors (SVs) to price variances using the stepwise multi-regression approach; and then it is to forecast the housing price variances by employing the SVs identified by the first step as well as other variables postulated by the hedonic price theory, where the housing prices in Taipei City are empirically examined to verify the designed framework. Results computed by nonparametric estimation confirm that the prediction power of using SVM in housing price forecasting is of high accuracy. Further studies are suggested to extract the geographical weights using kernel density estimates to reflect price responses to local quantiles of hedonic attributes. © 2017 Vilnius Gediminas Technical University (VGTU) Press.";Article;10.3846/1648715X.2016.1259190;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022191195&doi=10.3846%2f1648715X.2016.1259190&partnerID=40&md5=191a967df11c249f349beb94e2090072;"Institute of Construction Management and Management, National Central University, Taiwan; Department of Civil Engineering, Universiti Tunku Abdul Rahman, Malaysia; Department of Real Estate and Construction, The University of Hong Kong, Hong Kong; Department of Civil and Environmental Engineering, The Hong Kong Polytechnic University, Hong Kong";"Hedonic appraisal method;  Housing price forecasting;  Spatial dynamics;  Supporting vector machine";;;;;cited By 22;
47;S;Housing market hedonic price study based on boosting regression tree;Gu, G. and Xu, B.;Journal of Advanced Computational Intelligence and Intelligent Informatics;2017;Scopus;1040-1047;21;Based on the purchase price data of new real estate markets three cities in China, Beijing, Shanghai, and Guangzhou, including architectural features, neighborhood property features, and location features, in this study a boosting regression tree model was built to study the factors and the influence path of housing prices from the microcosmic perspective. First, a classical hedonic price model was constructed to analyze and compare the significant effect factors on housing prices in the market segments of the three cities. Second, the gradient boosting regression tree method that is proposed in this paper was applied to the three markets in combination to analyze the influence paths and factors and the importance of the type of housing hedonic price. The influence paths of housing hedonic prices and decision tree rules are visualized. The significant housing features are effectively extracted. Finally, we present three main conclusions and several suggestions for policy makers to improve urban functions while stabilizing real estate prices.;Article;10.20965/jaciii.2017.p1040;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032980777&doi=10.20965%2fjaciii.2017.p1040&partnerID=40&md5=94cf12d4127cd2e94f45bd4626cde01f;"Research Institute of Quantitative Economics, Zhejiang Gongshang University, Hangzhou, Zhejiang, 310018, China; School of Economics and Management, Zhejiang A and F University, Hangzhou, Zhejiang, 311300, China; Center for China Farmers' Development of Zhejiang lin'An, Hangzhou, Zhejiang, 311300, China";"Gradient boosting;  Machine learning;  Regression tree;  Residential hedonic price";;;;;cited By 4;
48;S;Homeowner preferences after September 11th, a microdata approach;Nowak, A. and Sayago-Gomez, J.;Regional Science and Urban Economics;2018;Scopus;330-351;70;"The existence of homeowner preferences – specifically homeowner preferences for neighbors – is fundamental to economic models of sorting. This paper investigates whether or not the terrorist attacks of September 11, 2001 (9/11) impacted local preferences for Arab neighbors. We test for changes in preferences using a differences-in-differences approach in a hedonic pricing model. Relative to sales before 9/11, we find properties within 0.1 miles of an Arab homeowner sold at a 1.4% discount (approximately $4133) in the 180 days after 9/11. The results are robust to a number of specifications including time horizon, event date, distance, time, alternative ethnic groups, and the presence of nearby mosques. Previous research has shown price effects at neighborhood levels but has not identified effects at the micro or individual property level, and for good reason: most transaction level data sets do not include ethnic identifiers. Applying methods from the machine learning and biostatistics literature, we develop a binomial classifier using a supervised learning algorithm and identify Arab homeowners based on the name of the buyer. We train the binomial classifier using names from Summer Olympic Rosters for 221 countries during the years 1948–2012. We demonstrate the flexibility of our methodology and perform an interesting counterfactual by identifying Hispanic and Asian homeowners in the data; unlike the statistically significant results for Arab homeowners, we find no meaningful results for Hispanic and Asian homeowners following 9/11. © 2017 Elsevier B.V.";Article;10.1016/j.regsciurbeco.2017.10.001;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033463432&doi=10.1016%2fj.regsciurbeco.2017.10.001&partnerID=40&md5=6701119ec540ac6ffb8f43901db28e05;"West Virginia University, Department of Economics, College of Business and Economics, 1601 University Dr PO Box 6025, Morgantown, WV  26506-6025, United States; Universidad Icesi, Department of Economics, School of Business and Economic Studies, Columbia, United States";"Ethnicity;  Homeowner preferences;  House prices;  September 11th;  Terrorism";;;;;cited By 2;
49;S;Identifying real estate opportunities using machine learning;Baldominos, A. and Blanco, I. and Moreno, A.J. and Iturrarte, R. and Bernárdez, Ó. and Afonso, C.;Applied Sciences (Switzerland);2018;Scopus;;8;The real estate market is exposed to many fluctuations in prices because of existing correlations with many variables, some of which cannot be controlled or might even be unknown. Housing prices can increase rapidly (or in some cases, also drop very fast), yet the numerous listings available online where houses are sold or rented are not likely to be updated that often. In some cases, individuals interested in selling a house (or apartment) might include it in some online listing, and forget about updating the price. In other cases, some individuals might be interested in deliberately setting a price below the market price in order to sell the home faster, for various reasons. In this paper, we aim at developing a machine learning application that identifies opportunities in the real estate market in real time, i.e., houses that are listed with a price substantially below the market price. This program can be useful for investors interested in the housing market. We have focused in a use case considering real estate assets located in the Salamanca district in Madrid (Spain) and listed in the most relevant Spanish online site for home sales and rentals. The application is formally implemented as a regression problem that tries to estimate the market price of a house given features retrieved from public online listings. For building this application, we have performed a feature engineering stage in order to discover relevant features that allows for attaining a high predictive performance. Several machine learning algorithms have been tested, including regression trees, k-nearest neighbors, support vector machines and neural networks, identifying advantages and handicaps of each of them. © 2018 by the authors.;Article;10.3390/app8112321;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057007680&doi=10.3390%2fapp8112321&partnerID=40&md5=62c9ef745ead3cb8cf65a756a8ccceea;"Computer Science Department, Universidad Carlos III de Madrid, Leganés, 28911, Spain; Artificial Intelligence Group, Rentier Token, Madrid, 28050, Spain; Finance Department, Colegio Universitario de Estudios Financieros, Madrid, 28040, Spain";"Appraisal;  Artificial intelligence;  Investment;  Machine learning;  Real estate";;;;;cited By 24;
50;S;Home is where the ad is: online interest proxies housing demand;Pangallo, M. and Loberto, M.;EPJ Data Science;2018;Scopus;;7;Online activity leaves digital traces of human behavior. In this paper we investigate if online interest can be used as a proxy of housing demand, a key yet so far mostly unobserved feature of housing markets. We analyze data from an Italian website of housing sales advertisements (ads). For each ad, we know the timings at which website users clicked on the ad or used the corresponding contact form. We show that low online interest—a small number of clicks/contacts on the ad relative to other ads in the same neighborhood—predicts longer time on market and higher chance of downward price revisions, and that aggregate online interest is a leading indicator of housing market liquidity and prices. As online interest affects time on market, liquidity and prices in the same way as actual demand, we deduce that it is a good proxy. We then turn to a standard econometric problem: what difference in demand is caused by a difference in price? We use machine learning to identify pairs of duplicate ads, i.e. ads that refer to the same housing unit. Under some caveats, differences in demand between the two ads can only be caused by differences in price. We find that a 1% higher price causes a 0.66% lower number of clicks. © 2018, The Author(s).;Article;10.1140/epjds/s13688-018-0176-2;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056363195&doi=10.1140%2fepjds%2fs13688-018-0176-2&partnerID=40&md5=096b4247c95c7f316aa5c293fc1e68e1;"Institute for New Economic Thinking at the Oxford Martin School, University of Oxford, Oxford, United Kingdom; Mathematical Institute, University of Oxford, Oxford, United Kingdom; Directorate General for Economics, Statistics and Research, Banca d’Italia, Roma, Italy";"Causality;  Econometrics;  Housing market;  Machine learning;  Online data";;;;;cited By 2;
51;S;RETSManager: Real-estate database builder and synchronizer;Hammad, I. and El-Sankary, K. and Hornibrook, H.;SoftwareX;2019;Scopus;;10;RETSManager is a Django based platform for retrieving, storing, and synchronizing real-estate data and images from multiple listing service (MLS) servers. This platform can be used to construct synchronized and up-to-date real-estate datasets for usage in research fields such as machine learning, image-based deep learning, and housing market statistical analysis. The platform converts and synchronizes the raw XML data originating from the MLS servers to a structure data in a PostgreSQL or SQLite database. Additionally, it supports storage and synchronization of images either on a local drive or on an Amazon Web Services (AWS) S3 bucket. The platform is production-ready and can be deployed as multiple Docker containers including a pre-configured Nginx container for web application support and Celery and Redis containers to supports scheduled periodic updates. © 2019 The Authors;Article;10.1016/j.softx.2019.100351;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074157513&doi=10.1016%2fj.softx.2019.100351&partnerID=40&md5=89b30332f68fceaa57d40554d86de468;"Dalhousie University, Halifax, NS, Canada; RE/MAX Professionals, Toronto, ON, Canada";"Django;  Machine learning;  Real estate;  RETS";;;;;cited By 1;
52;S;Sustainable profitability in volatile cyclical markets;Sarraf, H.;Journal of Risk Management in Financial Institutions;2020;Scopus;182-189;13;Market conditions are prone to change rapidly, limiting the ability of lenders to mitigate losses. Furthermore, lenders’ behaviour can often contribute to market volatility as lending initially drives up market leverage, and this is followed by greatly reduced credit supply following a market correction as capital constraints and heightened risk sensitivities constrict banks’ willingness to lend. This paper analyses how banks can successfully ensure it is being rewarded for the risk presented by a cyclical and volatile market. It also discusses how a bank can avoid presenting its shareholders with loss of their capital without missing profitable lending opportunities? In short, how should a bank seek commercial sustainability in volatile cyclical markets?. © Henry Stewart Publications 1752-8887 (2020).;Article;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084226805&partnerID=40&md5=33afb2dcc722bb9a54dad88a912fa607;Group Chief Risk Officer, BankMed Group, 482 Clemenceau Street, Beirut, 1107-2030, Lebanon;"Active credit portfolio management;  Concentration risk;  Credit losses, credit cycles;  Housing market;  IRB models;  Loan-to-value (LTV);  Loss forecasting;  Machine learning;  Procyclicality;  Real estate lending;  Risk measurement;  Risk segmentation;  Sustainable profitability";;;;;cited By 0;
53;S;A house price valuation based on the random forest approach: The mass appraisal of residential property in south korea;Hong, J. and Choi, H. and Kim, W.-S.;International Journal of Strategic Property Management;2020;Scopus;140-152;24;Mass appraisal is the standardized procedure of valuing a large number of properties at the same time and is commonly used to compute real estate tax. While a hedonic pricing model based on the ordinary least squares (OLS) linear regression has been employed as the traditional method in this process, the stability and accuracy of the model remain questionable. This paper investigates the features of a house price predictor based on the Random Forest (RF) method by comparing it with that of a conventional hedonic pricing model. We used apartment transaction data from the period of 2006 to 2017 in the district of Gangnam, one of the most developed areas in South Korea. Using a data set covering 40% of all transactions in the sample area, we demonstrate that the accuracy of a machine learning-based predictor can be surprisingly high. The average of percentage deviations between the predicted and the actual market price was found to be only around 5.5% in the RF predictor, whereas it was almost 20% in the OLS-based predictor. With the RF predictor, the probability of the predicted price being within 5% of its actual market price was 72%, while only about 17.5% of the regression-based predictions fell within the same range. These results show that, in the practice of mass appraisal, the RF method may be a useful complement to the hedonic models, as it more adequately captures the complexity or non-linearity of actual housing markets. © 2020 The Author(s). Published by VGTU Press.;Article;10.3846/ijspm.2020.11544;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082550830&doi=10.3846%2fijspm.2020.11544&partnerID=40&md5=cdf508ca03389b4b2aeb65e8820b36d8;"School of Management and Economics, Handong Global University, Pohang, South Korea; School of Computer Science and Electrical Engineering, Handong Global University, Pohang, South Korea";"Apartment;  Hedonic pricing model;  Housing price forecasting;  Machine learning technique;  Mass appraisal;  Random forest approach";;;;;cited By 12;
54;S;Applying comparable sales method to the automated estimation of real estate prices;Kim, Y. and Choi, S. and Yi, M.Y.;Sustainability (Switzerland);2020;Scopus;;12;In this paper, we propose a novel procedure designed to apply comparable sales method to the automated price estimation of real estates, in particular, that of apartments. Apartments are the most popular residential housing type in Korea. The price of a single apartment is influenced by many factors, making it hard to estimate accurately. Moreover, as an apartment is purchased for living, with a sizable amount of money, it is mostly traded infrequently. Thus, its past transaction price may not be particularly helpful to the estimation after a certain period of time. For these reasons, the up-to-date price of an apartment is commonly estimated by certified appraisers, who typically rely on comparable sales method (CSM). CSM requires comparable properties to be identified and used as references in estimating the current price of the property in question. In this research, we develop a procedure to systematically apply this procedure to the automated estimation of apartment prices and assess its applicability using nine years' real transaction data from the capital city and the most-populated province in South Korea and multiple scenarios designed to reflect the conditions of low and high fluctuations of housing prices. The results from extensive evaluations show that the proposed approach is superior to the traditional approach of relying on real estate professionals and also to the baseline machine learning approach. © 2020 by the authors.;Article;10.3390/su12145679;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088662419&doi=10.3390%2fsu12145679&partnerID=40&md5=b17f2026681117267faa163a0cf4a124;"Financial Supervisory Service, 38, Yeoui-daero, Yeongdeungpo-gu, Seoul, 07321, South Korea; Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea";"Boosting;  Comparable sales method;  Housing price estimation;  Machine learning;  Real estate valuation";;;;;cited By 7;
55;S;Assessing the impact of public rental housing on the housing prices in proximity: Based on the regional and local level of price prediction models using long short-term memory (LSTM);Kim, H. and Kwon, Y. and Choi, Y.;Sustainability (Switzerland);2020;Scopus;;12;"Providing adequate public rental housing (PRH) of a decent quality at a desirable location is a major challenge in many cities. Often, a prominent opponent of PRH development is its host community, driven by a belief that PRH depreciates nearby property values. While this is a persistent issue in many cities around the world, this study proposed a new approach to assessing the impact of PRH on nearby property value. This study utilized a machine learning technique called long short-term memory (LSTM) to construct a set of housing price prediction models based on 547,740 apartment transaction records from the city of Busan, South Korea. A set of apartment characteristics and proximity measures to PRH were included in the modeling process. Four geographic boundaries were analyzed: The entire region of Busan, all neighborhoods of PRH, the neighborhoods of PRH in the ""favorable,"" and the ""less favorable"" local housing market. The study produced accurate and reliable price predictions, which indicated that the proximity to PRH has a meaningful impact on nearby housing prices both at the city and the neighborhood level. The approach taken by the study can facilitate improved decision making for future PRH policies and programs. © 2020 by the authors.";Article;10.3390/su12187520;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091173734&doi=10.3390%2fsu12187520&partnerID=40&md5=11029667b4a578459faa26152f5f8b80;Department of Urban Planning and Engineering, Pusan National University, Busan, 46241, South Korea;"Housing market analysis;  Long short-term memory;  Price forecasting;  Public rental housing";;;;;cited By 1;
56;S;Real Estate Dictionaries Across Space and Time;Nowak, A.D. and Price, B.S. and Smith, P.S.;Journal of Real Estate Finance and Economics;2021;Scopus;139-163;62;Leveraging high-dimensional variable selection methods, we show the textual information provided in real estate agents’ remarks about a property can be used to address spatial and temporal heterogeneity in housing markets. Including the textual information in the pricing model decreases in-sample prediction errors by as much as 18.7% at the MSA-level and 39.1% at the zip code level. These results are robust to transforming the raw text using a real estate specific word list, the choice of n-grams, word stemming, and heteroscedasticity in the hedonic and repeat-sales models. These findings suggest the raw text in the remarks can be included directly in predictive pricing models. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.;Article;10.1007/s11146-019-09740-w;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077092451&doi=10.1007%2fs11146-019-09740-w&partnerID=40&md5=50ad28d168e4bb623923a05f5d0dcb9b;"John Chambers College of Business and Economics, West Virginia University, Morgantown, WV, United States; Fowler College of Business, San Diego State University, San Diego, CA, United States";"House prices;  Machine learning;  Real estate dictionary;  Textual analysis";;;;;cited By 1;
57;S;Predicting property prices with machine learning algorithms;Ho, W.K.O. and Tang, B.-S. and Wong, S.W.;Journal of Property Research;2021;Scopus;48-70;38;This study uses three machine learning algorithms including, support vector machine (SVM), random forest (RF) and gradient boosting machine (GBM) in the appraisal of property prices. It applies these methods to examine a data sample of about 40,000 housing transactions in a period of over 18 years in Hong Kong, and then compares the results of these algorithms. In terms of predictive power, RF and GBM have achieved better performance when compared to SVM. The three performance metrics including mean squared error (MSE), root mean squared error (RMSE) and mean absolute percentage error (MAPE) associated with these two algorithms also unambiguously outperform those of SVM. However, our study has found that SVM is still a useful algorithm in data fitting because it can produce reasonably accurate predictions within a tight time constraint. Our conclusion is that machine learning offers a promising, alternative technique in property valuation and appraisal research especially in relation to property price prediction. © 2020 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.;Article;10.1080/09599916.2020.1832558;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092761693&doi=10.1080%2f09599916.2020.1832558&partnerID=40&md5=533270da73aacdda2631114b77e0e249;"Department of Real Estate and Construction, The University of Hong Kong, Hong Kong; Department of Urban Planning and Design, The University of Hong Kong, Hong Kong; Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong";"GBM;  Machine Learning algorithms;  property valuation;  RF;  SVM";;;;;cited By 7;
58;S;Machine Learning Predictions of Housing Market Synchronization across US States: The Role of Uncertainty;Gupta, R. and Marfatia, H.A. and Pierdzioch, C. and Salisu, A.A.;Journal of Real Estate Finance and Economics;2021;Scopus;;;We analyze the role of macroeconomic uncertainty in predicting synchronization in housing price movements across all the United States (US) states plus District of Columbia (DC). We first use a Bayesian dynamic factor model to decompose the house price movements into a national, four regional (Northeast, South, Midwest, and West), and state-specific factors. We then study the ability of macroeconomic uncertainty in forecasting the comovements in housing prices, by controlling for a wide-array of predictors, such as factors derived from a large macroeconomic dataset, oil shocks, and financial market-related uncertainties. To accommodate for multiple predictors and nonlinearities, we take a machine learning approach of random forests. Our results provide strong evidence of forecastability of the national house price factor based on the information content of macroeconomic uncertainties over and above the other predictors. This result also carries over, albeit by a varying degree, to the factors associated with the four census regions, and the overall house price growth of the US economy. Moreover, macroeconomic uncertainty is found to have predictive content for (stochastic) volatility of the national factor and aggregate US house price. Our results have important implications for policymakers and investors. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.;Article;10.1007/s11146-020-09813-1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099368452&doi=10.1007%2fs11146-020-09813-1&partnerID=40&md5=184f97beb28e818734b54519be4ee0fc;"Department of Economics, University of Pretoria, Pretoria, 0002, South Africa; Department of Economics, Northeastern Illinois University, 5500 N St Louis Ave, BBH 344G, Chicago, IL  60625, United States; Department of Economics, Helmut Schmidt University, Holstenhofweg 85, P.O.B. 700822, Hamburg, 22008, Germany; Centre for Econometric & Allied Research, University of Ibadan, Ibadan, Nigeria";"Bayesian dynamic factor model;  Forecasting;  Housing markets synchronization;  Machine learning;  Random forests;  United States";;;;;cited By 2;
59;S;Machine learning for inference: using gradient boosting decision tree to assess non-linear effects of bus rapid transit on house prices;Yang, L. and Liang, Y. and Zhu, Q. and Chu, X.;Annals of GIS;2021;Scopus;273-284;27;The adoption of bus rapid transit (BRT) systems has gained worldwide popularity over the past several decades. China is no exception as it has long been aiming at promoting public transportation. Prior studies have provided extensive evidence that BRT has substantial effects on house prices with traditional econometric techniques, such as hedonic pricing models. However, few of those investigations have discussed the non-linear relationship between BRT and house prices. Using the Xiamen data, this study employs a machine learning technique, namely the gradient boosting decision tree (GBDT), to scrutinize the non-linear relationship between BRT and house prices. This study documents a positive association between accessibility to BRT stations and house prices and a negative association between proximity to the BRT corridor and house prices. Moreover, it suggests a non-linear relationship between BRT and house prices and indicates that GBDT has more substantial predictive power than hedonic pricing models. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group, on behalf of Nanjing Normal University.;Article;10.1080/19475683.2021.1906746;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103269805&doi=10.1080%2f19475683.2021.1906746&partnerID=40&md5=373bf1f78cc01428c9ef71a4f51b6314;"Southwest Jiaotong University, Chengdu, China; Urban Mobility Institute, Tongji University, Shanghai, China; Department of Real Estate and Construction, The University of Hong Kong, Hong Kong";"Bus Rapid Transit (BRT);  Gradient Boosting Decision Tree (GBDT);  hedonic pricing model;  House price;  machine learning";;;;;cited By 0;
60;S;Metrics for evaluating the performance of machine learning based automated valuation models;Steurer, M. and Hill, R.J. and Pfeifer, N.;Journal of Property Research;2021;Scopus;99-129;38;Automated Valuation Models (AVMs) based on Machine Learning (ML) algorithms are widely used for predicting house prices. While there is consensus in the literature that cross-validation (CV) should be used for model selection in this context, the interdisciplinary nature of the subject has made it hard to reach consensus over which metrics to use at each stage of the CV exercise. We collect 48 metrics (from the AVM literature and elsewhere) and classify them into seven groups according to their structure. Each of these groups focuses on a particular aspect of the error distribution. Depending on the type of data and the purpose of the AVM, the needs of users may be met by some classes, but not by others. In addition, we show in an empirical application how the choice of metric can influence the choice of model, by applying each metric to evaluate five commonly used AVM models. Finally–since it is not always practicable to produce 48 different performance metrics–we provide a short list of 7 metrics that are well suited to evaluate AVMs. These metrics satisfy a symmetry condition that we find is important for AVM performance, and can provide a good overall model performance ranking. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.;Article;10.1080/09599916.2020.1858937;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104549219&doi=10.1080%2f09599916.2020.1858937&partnerID=40&md5=9b6b8444632eff37c7f6879ca318ba31;Department of Economics, University of Graz, Graz, Austria;"automated valuation;  house price prediction;  machine learning;  model selection;  Performance metrics";;;;;cited By 2;
61;S;Automated Valuation Services: A case study for Aberdeen in Scotland;Schulz, R. and Wersing, M.;Journal of Property Research;2021;Scopus;154-172;38;Automated valuation services (AVSs) offered by listings platforms predict market values based on property characteristics supplied by users. We investigate the implementation of such a service for the City of Aberdeen. We fit different market value models with machine learning methods and assess them in a rolling windows procedure that mimics an AVS setting. We also investigate the ease and robustness with which the models can be implemented. We discuss how prediction uncertainty can be measured and reported to users. If implemented in the future, such a service has the potential to improve the transparency of the local housing market. © 2021 Informa UK Limited, trading as Taylor & Francis Group.;Article;10.1080/09599916.2020.1861066;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105154862&doi=10.1080%2f09599916.2020.1861066&partnerID=40&md5=57f4f37b46bb38bb99e472a3a9801cfc;University of Aberdeen Business School, Aberdeen, United Kingdom;"Housing market;  machine learning";;;;;cited By 1;
62;S;Learning low-dimensional structure in house price indices;Glynn, C.;Applied Stochastic Models in Business and Industry;2021;Scopus;;;"House price indices (HPIs) are statistical measures of real estate price dynamics in defined geographic regions over defined periods of time. HPIs are important metrics that help policymakers, mortgage lenders, real estate investors, and bank regulators monitor market conditions and manage risk. HPIs that are local, reliable, and timely are essential in understanding connections between housing markets and the broader economy. In this article, we examine the algorithmic construction of Zillow's Home Value Index (ZHVI), an HPI built on black box machine learning algorithms. To provide deeper statistical insight into ZHVI than afforded by its black box construction, we develop a Bayesian generative meta-model that approximates the black box construction of ZHVI series in 100 metropolitan areas (metros). Each ZHVI series is modeled with a global trend, a finite mixture of Gaussian processes, and a local component. We find that there are three shared dynamic patterns across the 100 markets in our analysis, and we utilize this shared latent structure to forecast ZHVI in each metro 12 months ahead. Our clustering strategy has two advantages: (i) it allows us to construct composite HPIs where member metros are learned from the data rather than predetermined; and (ii) it allows us to estimate the relative contributions of cluster-level and metro-specific components to a metro's ZHVI, providing a novel statistical attribution of real estate market dynamics. © 2021 John Wiley & Sons, Ltd.";Article;10.1002/asmb.2653;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117803736&doi=10.1002%2fasmb.2653&partnerID=40&md5=475a2accc0ef24f9c66547c13913d7ea;Zillow Research, Seattle, WA, United States;"Bayesian analysis;  dynamic linear model;  Gaussian process;  house price index;  Markov chain Monte Carlo";;;;;cited By 0;
63;S;The effect of hazard shock and disclosure information on property and land prices: a machine-learning assessment in the case of Japan;Peng, T.-C.;Review of Regional Research;2021;Scopus;;41;"The occurrence of 6.7-magnitude Hokkaido Eastern Iburi Earthquake on 6th September 2018 made local residents in Japan realise the underneath hazardous threat to their own safety and residential dwellings. Japan has faced various natural disasters for a long time, and Government chose to unveil these hazard data in details to the public to raise every one’s alertness. Despite their long-term awareness of hazards, this short-term unexpected event should have impact on local real estate markets. Given the transaction data of properties and lands, this study used machine-learning algorithms to examine whether the unexpected hazard shock (i.e. 2018 Hokkaido Earthquake) or the observed local hazard information in geographic areas (i.e. long-term evaluation of each real estate) would be capitalised into the prices of residential properties and lands in the case of Hokkaido, Japan. It is assumed that the difference in the characteristics of disaster notification would alter individuals’ risk perception and thus the evaluation of properties; compared to uncertain, infrequent occurrence of earthquakes in the unknown future (i.e. beyond the scope of objective estimation), the release of long-term hazardous information (tied to each property or land), which is more perceivable in near future, is more likely to be capitalised into real estate. It is found that housing/land attributes are still the key features to real estate values in Hokkaido. In comparison with short-term unexpected hazard shock (i.e. 2018 Earthquake), the long-term hazard threats are more influential to prices of properties and lands. This is possibly due to people’s awareness of the hazard conditions of local communities while deciding where to reside. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature.";Article;10.1007/s10037-020-00148-1;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099747988&doi=10.1007%2fs10037-020-00148-1&partnerID=40&md5=9f2a22fd8ae4a099b2fea3a06c630e59;Department of Real Estate and Built Environment, National Taipei University, 151, University Rd., New Taipei City, San Shia District  23741, Taiwan;"Japan;  Land prices;  Machine-learning algorithms;  Natural hazard;  Property prices";;;;;cited By 1;
64;S;Data-driven preference learning methods for value-driven multiple criteria sorting with interacting criteria;Liu, J. and Kadzinski, M. and Liao, X. and Mao, X.;INFORMS Journal on Computing;2021;Scopus;586-606;33;The learning of predictive models for data-driven decision support has been a prevalent topic in many fields. However, construction of models that would capture interactions among input variables is a challenging task. In this paper, we present a new preference learning approach for multiple criteria sorting with potentially interacting criteria. It employs an additive piecewise-linear value function as the basic preference model, which is augmented with components for handling the interactions. To construct such a model from a given set of assignment examples concerning reference alternatives, we develop a convex quadratic programming model. Because its complexity does not depend on the number of training samples, the proposed approach is capable for dealing with data-intensive tasks. To improve the generalization of the constructed model on new instances and to overcome the problem of overfitting, we employ the regularization techniques. We also propose a few novel methods for classifying nonreference alternatives in order to enhance the applicability of our approach to different data sets. The practical usefulness of the proposed approach is demonstrated on a problem of parametric evaluation of research units, whereas its predictive performance is studied on several monotone classification problems. The experimental results indicate that our approach compares favourably with the classical UTilités Additives DIScriminantes (UTADIS) method and the Choquet integral-based sorting model. Summary of Contribution. The paper tackles vital challenges at the intersections of multiple criteria decision analysis and machine learning, showing how computationally advanced techniques can be used for faithfully representing human preferences and dealing with complex decision problems. Specifically, we propose a novel preference learning method for multiple criteria sorting problems. The introduced approach incorporates convex quadratic programming to construct a value-based preference model based on large sets of preference statements. In this way, we extend the applicability of decision analysis methods to preferences derived from historical data or observation of users’ behavior in addition to the preference judgments explicitly revealed by the decision-makers. The method’s practical usefulness is illustrated on a variety of real-world datasets from fields such as higher education, medicine, human resources, and housing market. Its potential for supporting better decision-making is enhanced by both an interpretable form of the assumed model handling interactions between criteria as well as a high predictive performance demonstrated in the extensive computational experiments. Copyright: © 2020 INFORMS;Article;10.1287/ijoc.2020.0977;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099546038&doi=10.1287%2fijoc.2020.0977&partnerID=40&md5=2714c77e29fd1095c10c500f32c1b400;"School of Management, Center of Intelligent Decision Making and Machine Learning, Xi’an Jiaotong University, Shaanxi, Xi’an, 710049, China; Institute of Computing Science, Poznan University of Technology, Poznan, 60-965, Poland; School of Management, Center of Intelligent Decision Making and Machine Learning, Xi’an Jiaotong University, Shaanxi, Xi’an, 710049, China; School of Management, Xi’an Jiaotong University, Shaanxi, Xi’an, 710049, China";"Additive value function;  Decision analysis;  Interacting criteria;  Ordinal classification;  Preference learning;  Sorting";;;;;cited By 3;
65;S;Modeling fine-scale residential land price distribution: An experimental study using open data and machine learning;Zhang, P. and Hu, S. and Li, W. and Zhang, C. and Yang, S. and Qu, S.;Applied Geography;2021;Scopus;;129;"Modeling the fine-scale spatiotemporal distribution of residential land prices (RLPs) is the basis for scientifically allocating land resources, managing the residential market and improving urban planning. The accurate mapping of the RLP dynamics require reliable land price prediction models and data with fine spatial and temporal resolution. With the aid of point of interest (POI) data and nighttime light (NTL) images, this paper attempts to explore the ability of machine learning algorithms (MLAs) to model grid-level RLPs using the case of Wuhan in China. Several land price prediction models were built using five MLAs and various geographic variables. The experimental results show that the extra-trees regression algorithm and the radial basis function-based support vector regression algorithm perform best in Period ? (2010–2014) and Period ? (2015–2019), respectively; therefore, they were selected to estimate the RLPs of the grids without observations in the corresponding period. Based on the estimated results, we found that the spatial pattern of the RLP in Wuhan transitioned from monocentric to polycentric between the two periods, and RLPs grew rapidly near newly formed urban subcenters and waterscapes. The relative importance of the predictor variables shows that commercial and educational facilities are important determinants of the RLP distribution in Wuhan; moreover, the relative importance of natural amenities and education facilities increased over time, while that of commercial facilities and public transportation decreased slightly. The case of Wuhan confirms the feasibility of MLAs and openly accessible urban data in modeling fine-scale RLP distributions. Our proposed framework provides a new approach to monitor the urban land price dynamics accurately and closely, which is beneficial for improving the infrastructure layout and achieve smart city growth. © 2021 Elsevier Ltd";Article;10.1016/j.apgeog.2021.102442;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103982388&doi=10.1016%2fj.apgeog.2021.102442&partnerID=40&md5=bfcbf0cd935db31dfe47bd5f8b66cfea;"Department of Land Resources Management, China University of Geosciences (CUG), Wuhan, 430074, China; Department of Geography, University of Connecticut, Storrs, CT  06269, United States; Key Laboratory for Rule of Law Research, Ministry of Natural Resources, Wuhan, 430074, China";"Determinants;  Land price distribution;  Machine learning;  Open data;  Spatiotemporal variation;  Wuhan";;;;;cited By 1;
66;S;Bayesian MIDAS penalized regressions: Estimation, selection, and prediction;Matteo Mogliani and Anna Simoni;Journal of Econometrics;2021;Science@Direct;833-860;222;We propose a new approach to mixed-frequency regressions in a high-dimensional environment that resorts to Group Lasso penalization and Bayesian estimation and inference. In particular, to improve the prediction properties of the model and its sparse recovery ability, we consider a Group Lasso with a spike-and-slab prior. Penalty hyper-parameters governing the model shrinkage are automatically tuned via an adaptive MCMC algorithm. We establish good frequentist asymptotic properties of the posterior prediction error, we recover the optimal posterior contraction rate, and we show optimality of the posterior predictive density. Simulations show that the proposed models have good selection and forecasting performance in small samples, even when the design matrix presents cross-correlation. When applied to forecasting U.S. GDP, our penalized regressions can outperform many strong competitors. Results suggest that financial variables may have some, although very limited, short-term predictive content.;;https://doi.org/10.1016/j.jeconom.2020.07.022;https://www.sciencedirect.com/science/article/pii/S0304407620302207;;;Bayesian MIDAS regressions, Penalized regressions, Predictive distribution, Forecasting, Posterior contraction;;0304-4076;;;
67;S;Involving occupants in net-zero-energy solar housing retrofits: An Australian sub-tropical case study;Wendy Miller and Lei Aaron Liu and Zakaria Amin and Matthew Gray;Solar Energy;2018;Science@Direct;390-404;159;Australia has a poor record of enforcement and compliance with national energy efficiency building regulations introduced in 2003 and moderately enhanced several times since. A significant challenge facing the nation and owners/occupiers of poor performing houses is how to retrofit the existing building stock to meet thermal comfort, lifestyle, energy efficiency and climate mitigation expectations and standards now and into the future. The purpose of this study was to test a strategy for providing a range of information to the home owner to assist in their renovation decisions to achieve a net zero energy home in sub-tropical Australia and to evaluate the impact of their decisions in terms of net energy balance. A decision-making equation, rather than an economic-rationalist cost equation, was used to evaluate household actions. The results show that a combination of a citizen science approach, simulation tools and experimental data assisted occupants in achieving a 50% improvement in building thermal efficiency, an annual average daily consumption of 20.1?kWh and solar generation of 19.6?kWh. The cost of these actions was well under the average retrofit budget in Australia and resulted in the house achieving near net zero energy (NZE) balance for all household services on an annual basis and NZE balance for nine months of the year. Analysis of the motivations and actions of the home owner point to implications for building assessment tools, eco-feedback technologies, policy, and theories of household decision making.;;https://doi.org/10.1016/j.solener.2017.10.008;https://www.sciencedirect.com/science/article/pii/S0038092X17308733;;;Decision making, Net zero energy house, Retrofit, Rooftop PV, Thermal comfort;;0038-092X;;;
68;S;Social Infrastructure supporting Ambient Assisted Living in a Smart Silver City: Literature Review and Research Agenda;David Bogataj and Valerija Rogelj and Alenka Temeljotov Salaj;IFAC-PapersOnLine;2021;Science@Direct;942-947;54;Cities in EU member states are ageing. The increasing number of older urban residents have difficulties with basic activities of daily living due to physical and cognitive functional decline. Therefore, the demand for long-term care services in urban areas is rising. In the last 20 years, emerging technologies such as wireless communication, Internet of Things (IoT), sensors, ambient intelligence and cloud computing have opened up the possibilities of developing cyber-physical systems with various applications supporting older adults to remain physically and mentally active and live autonomously while being engaged in their communities. This paper shows that social infrastructure is an under-researched area of a smart city compared with digital infrastructure, transport infrastructure and utilities. This paper aims to review the digital transformation of social infrastructure for older adults in a smart city based on ambient assisted living technologies and propose a future research agenda.;;https://doi.org/10.1016/j.ifacol.2021.08.111;https://www.sciencedirect.com/science/article/pii/S2405896321008636;;;smart city, ambient assisted living, health care, social care, social infrastructure;;2405-8963;;17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021;
69;S;Bayesian nonparametric vector autoregressive models;Maria Kalli and Jim E. Griffin;Journal of Econometrics;2018;Science@Direct;267-282;203;Vector autoregressive (VAR) models are the main work-horse models for macroeconomic forecasting, and provide a framework for the analysis of complex dynamics that are present between macroeconomic variables. Whether a classical or a Bayesian approach is adopted, most VAR models are linear with Gaussian innovations. This can limit the model’s ability to explain the relationships in macroeconomic series. We propose a nonparametric VAR model that allows for nonlinearity in the conditional mean, heteroscedasticity in the conditional variance, and non-Gaussian innovations. Our approach differs from that of previous studies by modelling the stationary and transition densities using Bayesian nonparametric methods. Our Bayesian nonparametric VAR (BayesNP-VAR) model is applied to US and UK macroeconomic time series, and compared to other Bayesian VAR models. We show that BayesNP-VAR is a flexible model that is able to account for nonlinear relationships as well as heteroscedasticity in the data. In terms of short-run out-of-sample forecasts, we show that BayesNP-VAR predictively outperforms competing models.;;https://doi.org/10.1016/j.jeconom.2017.11.009;https://www.sciencedirect.com/science/article/pii/S0304407617302415;;;Vector autoregressive models, Dirichlet process prior, Infinite mixtures, Markov chain Monte Carlo;;0304-4076;;;
70;S;Forecasting using heterogeneous panels with cross-sectional dependence;Oguzhan Akgun and Alain Pirotte and Giovanni Urga;International Journal of Forecasting;2020;Science@Direct;1211-1227;36;In this paper, we focus on forecasting methods that use heterogeneous panels in the presence of cross-sectional dependence in terms of both spatial error dependence and common factors. We propose two main approaches to estimating the factor structure: a residuals-based approach, and an approach that uses a panel of auxiliary variables to extract the factors. Small sample properties of the proposed methods are investigated through Monte Carlo simulations and applied to predict house price inflation in OECD countries.;;https://doi.org/10.1016/j.ijforecast.2019.11.007;https://www.sciencedirect.com/science/article/pii/S0169207019302687;;;Cross-sectional dependence, Common factors, Spatial dependence, House price inflation, Inflation forecasting, Macroeconomic forecasting;;0169-2070;;;
71;S;The predictability of house prices: “human against machine”;Birkeland, K.B. and D’silva, A.D. and Füss, R. and Oust, A.;International Real Estate Review;2021;Scopus;139-183;24;We develop an automated valuation model (AVM) for the residential real estate market by leveraging stacked generalization and a comparable market analysis. Specifically, we combine four novel ensemble learning methods with a repeat sales method and tailor the data selection for each value estimate. We calibrate and evaluate the model for the residential real estate market in Oslo by producing out-of-sample estimates for the value of 1,979 dwellings sold in the first quarter of 2018. Our novel approach of using stacked generalization achieves a median absolute percentage error of 5.4%, and more than 96% of the dwellings are estimated within 20% of their actual sales price. A comparison of the valuation accuracy of our AVM to that of the local estate agents in Oslo generally demonstrates its viability as a valuation tool. However, in stable market phases, the machine falls short of human capability. © 2021, Global Social Science Institute. All rights reserved.;Article;;https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111338269&partnerID=40&md5=c15b6edb9609974d3c3368943dcb3fa7;"NTNU, Department of Industrial Economics and Technology Management, Norwegian University of Science and Technology (NTNU), Gløshaugen, Trondheim, NO7491, Norway; Swiss Institute of Banking and Finance (s/bf), University of St.Gallen, Unterer Graben 21, St.Gallen, CH-9000, Switzerland; Center for Real Estate and Environmental Economics, NTNU Business School, Trondheim, Norway; Centre for European Economic Research (ZEW), Mannheim, Germany; NTNU Business School, Norwegian University of Science and";"AVMs;  Housing market;  Machine learning;  Repeat sales approach;  XGBoost";;;;;cited By 0;
72;S;The impact of host race and gender on prices on Airbnb;Anya Marchenko;Journal of Housing Economics;2019;Science@Direct;101635;46;This study investigates the impact of host race and gender on Airbnb property prices. I use an existing dataset of Airbnb listings and visually inspect 70,000 host profile pictures to code host demographics. I estimate that Asian hosts earn 4–5%, and Black male hosts 3%, less than White males for the same type of property. However, controlling for more observables weakens the effects, requiring a cautious interpretation of these point estimates. I use two proxies for the number of bookings a listing has to estimate whether a demand or supply shift is responsible for the price disparity. I find that despite the lower prices they charge for listings, minority hosts face lower demand. These findings are consistent with, but not conclusive of, the presence of discrimination.;;https://doi.org/10.1016/j.jhe.2019.101635;https://www.sciencedirect.com/science/article/pii/S1051137718301815;;;Airbnb, Discrimination, Race, Online marketplace;;1051-1377;;;
73;S;Fuzzy regression analysis: Systematic review and bibliography;Nataliya Chukhrova and Arne Johannssen;Applied Soft Computing;2019;Science@Direct;105708;84;Statistical regression analysis is a powerful and reliable method to determine the impact of one or several independent variable(s) on a dependent variable. It is the most widely used of all statistical methods and has broad applicability to numerous practical problems. However, various problems can arise, when for instance the sample size is too small, distributional assumptions are not fulfilled, the relationship between independent and dependent variables is vague or when there is an ambiguity of events. Moreover, the complexity of real-life problems often makes the underlying models inadequate, since information is frequently imprecise in many ways. To relax these rigidities, numerous researchers have modified and extended concepts of statistical regression analysis by means of concepts of fuzzy set theory. By now, there is a large number of papers on the topic of fuzzy regression analysis, especially concerning possibilistic, fuzzy least squares or machine learning approaches. Additionally, the variety of approaches includes probabilistic, logistic, type-2 and clusterwise fuzzy regression methods, among many others. Besides papers mainly devoted to advances in methodology, there are also several papers presenting case studies in various research fields. To structure this diversity of papers, proposals and applications we give in this paper a comprehensive systematic review and provide a bibliography on the topic of fuzzy regression analysis. Thus, the paper intends to consolidate the topic in order to aid new researchers in this area, focuses the field’s attention on key open questions, and highlights possible directions for future research.;;https://doi.org/10.1016/j.asoc.2019.105708;https://www.sciencedirect.com/science/article/pii/S1568494619304892;;;Fuzzy least squares regression, Fuzzy linear regression, Fuzzy nonlinear regression, Interval regression, Machine learning techniques, Possibilistic regression;;1568-4946;;;
74;S;Do landscape amenities impact private housing rental prices? A hierarchical hedonic modeling approach based on semantic and sentimental analysis of online housing advertisements across five Chinese megacities;Shiliang Su and Shenjing He and Chenxi Sun and Hui Zhang and Lirong Hu and Mengjun Kang;Urban Forestry & Urban Greening;2021;Science@Direct;126968;58;Real estate premium associated with landscape amenities is a well-studied topic with a primary focus on housing prices. Presumably, the willingness-to-pay for landscape amenities should be very different between homeowners and tenants. Thus far, how landscape amenities affect residential rental prices is not well understood. This paper takes advantage of the big data of online housing advertisements to unravel how landscape amenities are capitalized into rental prices across five Chinese megacities (Beijing, Shanghai, Shenzhen, Hangzhou and Wuhan). Natural language processing, the latent Dirichlet allocation in particular, is first employed to semantically analyze the geo-textual advertisements. It reveals that ‘landscape amenities’ is a typical topic and ‘park’ is a typical component for housing advertisements in the five megacities. The lexicon-based sentimental analysis further shows that the strength of the sentiments associated with the ‘landscape amenities’ varies with cities. A series of hierarchical hedonic models based on the extracted semantic and sentimental aspects are then established for each megacity after segmenting the rental market into submarkets. The capitalization effect of landscape amenities is significant in Beijing, Hangzhou and Wuhan, while it is not significant in Shanghai and Shenzhen. Finally, variance decomposition analysis and marginal implicit price calculation unveil to what extent landscape amenities contribute to residential rental prices. Based on these findings, we discuss several major implications for urban planning. Our study unsettles the popular presumption that landscape amenities are key determinants of real estate values. It renews our understanding of the economic values of landscape amenities theoretically and methodologically.;;https://doi.org/10.1016/j.ufug.2020.126968;https://www.sciencedirect.com/science/article/pii/S1618866720307858;;;Hedonic pricing model, Housing rental price, Housing segmentation, Landscape amenities, Online housing listings, Semantic and sentimental analysis;;1618-8667;;;
75;S;A comparison of economic agent-based model calibration methods;Donovan Platt;Journal of Economic Dynamics and Control;2020;Science@Direct;103859;113;Despite significant expansion in recent years, the literature on quantitative and data-driven approaches to economic agent-based model validation and calibration consists primarily of studies that have focused on the introduction of new calibration methods that are neither benchmarked against existing alternatives nor rigorously tested in terms of the quality of the estimates they produce. In response, we compare a number of prominent agent-based model calibration methods, both established and novel, through a series of computational experiments in an attempt to determine the respective strengths and weaknesses of each approach. Overall, we find that a simple, likelihood-based approach to Bayesian estimation consistently outperforms several members of the more popular class of simulated minimum distance methods and results in reasonable parameter estimates in many contexts, with a degradation in performance observed only when considering a large-scale model and attempting to fit a substantial number of its parameters.;;https://doi.org/10.1016/j.jedc.2020.103859;https://www.sciencedirect.com/science/article/pii/S0165188920300294;;;Agent-based modelling, Calibration, Simulated minimum distance, Bayesian estimation;;0165-1889;;;
76;S;Are people happier in locations of high property value? Spatial temporal analytics of activity frequency, public sentiment and housing price using twitter data;Mark Junjie Tan and ChengHe Guan;Applied Geography;2021;Science@Direct;102474;132;"The rise of social networking platforms provides opportunities to examine the relationship between public emotion and housing price. This study investigates frequency and places of visits, population sentiment, and housing price using 8.7 million tweets retrieved from Manhattan, New York City in 2019. We implemented kernel density estimation, Getis-Ord Gi hot spot analysis, and spatial lagged hedonic pricing models to identify the location variation of sentiment levels. The results show: (1) the spatial clustering of tweets frequency was highly related to land use types in places such as parks, financial districts, and train stations; (2) high sentiment levels coincided with high frequency clusters and higher positive sentiment is associated with higher housing price; and (3) sentiment level was significantly associated with housing price and building structure, amenities, and proximity to landmarks all had significant influences on housing price. The study indicates that a population with higher concentration of happiness correlates to higher property value and provides an innovative perspective to understand public sentiment in relation to housing price using social media data, supplemented by housing transaction data. We demonstrate a feasible framework for researchers and stakeholders to utilize in future urban and spatial geographical research.";;https://doi.org/10.1016/j.apgeog.2021.102474;https://www.sciencedirect.com/science/article/pii/S0143622821000904;;;Twitter sentiment level, Social media data, Housing price, Spatial temporal analytics, New York city;;0143-6228;;;
77;S;Urban expansion and wetland shrinkage estimation using a GIS-based model in the East Kolkata Wetland, India;Biswajit Mondal and Gour Dolui and Malay Pramanik and Santu Maity and Sumantra Sarathi Biswas and Raghunath Pal;Ecological Indicators;2017;Science@Direct;62-73;83;The usefulness and need for wetland ecosystems are in general, manifold. Nonetheless, their current situation in many parts of the world is truly a matter of concern, both in terms of biodiversity as well as human well-being. While policy development and decision-making are vital, there is also a great need to understand the wetlands transition process, taking into account measures for their conservation. In an attempt towards such an understanding, this study analyses the eco-social transformation of the East Kolkata Wetland (EKW). As a primary step to examine the patterns and drivers of wetland change in the EKW, land cover changes have been quantified. In addition, the significance of the driving factors has been adjudged and modelled using Wetland Shrinkage Monitoring (WSM) model. The outcome shows that wetland shrinkage largely determined by proximity forces of urban growth. While the Markov transition indicates that 46% out of 38km2 wetland tends to alter to other classes, wetland transition 2025 points out that almost 9km2 area is at critical risk. In addition to these findings, the study ascertains that a decent functioning of the local authorities and a comprehensive land use planning are indispensable to curb wetland degradation.;;https://doi.org/10.1016/j.ecolind.2017.07.037;https://www.sciencedirect.com/science/article/pii/S1470160X17304508;;;East Kolkata wetland, SimWeight, Urban growth, Wetland shrinkage monitoring (WSM) model, Wetland transition;;1470-160X;;;
78;S;Identification of the numerical patterns behind the leading counties in the U.S. local green building markets using data mining;Jun Ma and Jack C.P. Cheng;Journal of Cleaner Production;2017;Science@Direct;406-418;151;The U.S. is reported to have one of the most developed green building markets. The country wide success must start from the success of different local markets. So how many important local green building markets are there in the U.S. and why those areas became important? The answers can provide useful implications for developing countries like China to better promote their green building markets. To explore the question in a numerical way, this study therefore collected the data of 17,636 green building projects in the U.S., clustered them into 39 important regions, and analyzed the numerical patterns behind based on 82 different features covering demography, economy, education, climate and policy. Non-linear machine learning algorithms help find that economic factors and educational factors are one of the most influential features. Discoveries were also implemented in China to suggest 20 areas to be the focus of developing Chinese green building market.;;https://doi.org/10.1016/j.jclepro.2017.03.083;https://www.sciencedirect.com/science/article/pii/S0959652617305176;;;Classification, Clustering, Green building market, Influential feature analysis, Greedy forward search;;0959-6526;;;
79;S;M&MFCM: Fuzzy C-means Clustering with Mahalanobis and Minkowski Distance Metrics;Natacha Gueorguieva and Iren Valova and George Georgiev;Procedia Computer Science;2017;Science@Direct;224-233;114;"The proposed modification of conventional fuzzy C-means clustering (FCM) algorithm aims to correct some of its shortcomings. We have focused on as missing flexibility in cluster number adaptation; limited cluster type grouping; less than optimal objective function for clusters of unequal size lying very close to each other; considerable computational time particularly in case of high dimensional data. With M&MFCM we propose to replace the usual Euclidean distance with Mahalanobis and Minkowski metrics in order to enhance the cluster detection capacity of FCM by allowing more accurate detection of arbitrary shapes of clusters for high dimensional datasets. Direct replacement of Euclidean distance in the objective function of FCM with Mahalanobis might cause numerical problems as the largest eigenvalues of the fuzzy covariance matrix could produce extremely long clusters thus contradicting the real data distribution. The improvement is achieved by fixing the ratio between the maximal and minimal eigenvalues of the covariance matrix. The parameterized Minkowski distance metric is adapted for implementation with FCM with various settings. We also propose an approach for improving the initial choice of cluster number and for visualization and analysis of cluster results for labeled and unlabeled datasets. Experimental results demonstrate that the proposed M&MFCM and test methodology significantly improve FCM clustering results.";;https://doi.org/10.1016/j.procs.2017.09.064;https://www.sciencedirect.com/science/article/pii/S1877050917318689;;;fuzzy clustering, cluster validation, distance metric, Silhouette function, confusion matrix, mapping;;1877-0509;;Complex Adaptive Systems Conference with Theme: Engineering Cyber Physical Systems, CAS October 30 – November 1, 2017, Chicago, Illinois, USA;
80;S;Robust Discovery of Regression Models;Jennifer L. Castle and Jurgen A. Doornik and David F. Hendry;Econometrics and Statistics;2021;Science@Direct;;;"Successful modeling of observational data requires jointly discovering the determinants of the underlying process and the observations from which it can be reliably estimated, given the near impossibility of pre-specifying both. To do so requires avoiding many potential problems, including substantive omitted variables; unmodeled non-stationarity and misspecified dynamics in time series; non-linearity; and inappropriate conditioning assumptions, as well as incorrect distributional shape combined with contaminated observations from outliers and shifts. The aim is to discover robust, parsimonious representations that retain the relevant information, are well specified, encompass alternative models, and evaluate the validity of the study. An approach is proposed that provides robustness in many directions. It is demonstrated how to handle apparent outliers due to alternative distributional assumptions; and discriminate between outliers and large observations arising from non-linear responses. Two empirical applications, utilizing datasets popularized in previous applications, show substantive improvements from the proposed approach to robust model discovery.";;https://doi.org/10.1016/j.ecosta.2021.05.004;https://www.sciencedirect.com/science/article/pii/S2452306221000629;;;Autometrics, Lasso, Least-trimmed Squares, Location Shifts, Model Discovery, Non-linearities, Outliers, Robustness, Saturation Estimation, Structural Breaks;;2452-3062;;;
81;S;A human-scale investigation into economic benefits of urban green and blue infrastructure based on big data and machine learning: A case study of Wuhan;Jia Jia and Xiaoqing Zhang;Journal of Cleaner Production;2021;Science@Direct;128321;316;"Rapid urbanization not only helps the urban economy achieve rapid growth but also imposes great pressure on resources and the environment. The green and blue infrastructure (GBI) in urban areas appears to be an important measure to enhance the economic benefits of the urban environment, but related research is still limited. In this article, we combine big data and machine learning methods to investigate the economic benefits of GBI in the city of Wuhan in Hubei Province. Specifically, the daily travel routes of citizens are analyzed at two scale levels (the housing and neighborhood scales); in our analysis, we start with the structural attributes of citizens’ own houses, move on to the city street views that citizens walk through, pass by the locational amenities where citizens spend their leisure time, and arrive at open spaces located throughout the city. The above trajectory dataset includes 30 variables, which were used as the input into ordinary least squares (OLS), geographically weighted regression (GWR), and multiscale GWR (MGWR). The results show that MGWR (adj. R2 = 0.524 at the housing scale, while adj. R2 = 0.869 at the neighborhood scale) with all control variables and the GBI attribute variables have the highest goodness of fit: the closer GBI is to urban residents, the higher the economic benefits are regardless of the area; and the higher the street visible green rate is, the greater the economic benefits are. Therefore, urban areas can appropriately increase the number of well-designed small GBIs located near urban residents. Our research provides insights into how big data and machine learning can be employed in frameworks to characterize the economic benefits of GBI and can be applied in other countries and regions.";;https://doi.org/10.1016/j.jclepro.2021.128321;https://www.sciencedirect.com/science/article/pii/S0959652621025361;;;Economic benefits, Green and blue infrastructure (GBI), Hedonic price model (HPM), Human-scale, Multiscale geographically weighted regression (MGWR);;0959-6526;;;
82;S;Modeling and predicting U.S. recessions using machine learning techniques;Spyridon D. Vrontos and John Galakis and Ioannis D. Vrontos;International Journal of Forecasting;2021;Science@Direct;647-671;37;The most representative machine learning techniques are implemented for modeling and forecasting U.S. economic activity and recessions in particular. An elaborate, comprehensive, and comparative framework is employed in order to estimate U.S. recession probabilities. The empirical analysis explores the predictive content of numerous well-followed macroeconomic and financial indicators, but also introduces a set of less-studied predictors. The predictive ability of the underlying models is evaluated using a plethora of statistical evaluation metrics. The results strongly support the application of machine learning over more standard econometric techniques in the area of recession prediction. Specifically, the analysis indicates that penalized Logit regression models, k-nearest neighbors, and Bayesian generalized linear models largely outperform ‘original’ Logit/Probit models in the prediction of U.S. recessions, as they achieve higher predictive accuracy across long-, medium-, and short-term forecast horizons.;;https://doi.org/10.1016/j.ijforecast.2020.08.005;https://www.sciencedirect.com/science/article/pii/S0169207020301205;;;Forecasting, Recession, Binary Probit/Logit, Classification and regression trees, Penalized likelihood models;;0169-2070;;;
83;S;Deriving adequate sample sizes for ANN-based modelling of real estate valuation tasks by complexity analysis;Sabine Horvath and Matthias Soot and Sebastian Zaddach and Hans Neuner and Alexandra Weitkamp;Land Use Policy;2021;Science@Direct;105475;107;Property valuation in areas with few transactions on basis of a linear regression fails due to a not sufficient number of purchasing cases. One approach which is enhancing the available data set is to evaluate these purchasing cases together with a neighbouring submarket. However, it leads to non-linearities. Consequently, non-linear models for a cross-submarket real estate valuation are required to obtain reasonable results. We focus in this contribution on non-linear modelling on basis of artificial neural networks (ANN). A prerequisite for these procedures is an adequate sample size. We present a new approach based on the aggregation of submarkets additional to the markets with few transactions at the expense of increasing complexity of the model required. The cross-submarket ANN estimation aims to reach accuracies comparable to local property valuation procedures in a first step and in further consequence to enable a reasonable estimation in areas with few transactions. We introduce an extended Kalman filter (EKF) estimation procedure for the ANN parameters and compare it to the standard optimisation procedure Levenberg Marquardt (LM) as well as to the multiple linear regression. Thus, German spatial and functional submarkets are aggregated. For the spatially aggregated data set, the ANN estimation leads to improved results. The ANN estimation of the functionally aggregated data appears deceptively simple due to too small samples not representing the sampling density. The question arises, what are adequate sample sizes regarding the complexity of the unknown relationship. We purpose a model complexity analysis procedure based on resampling and the structural risk minimisation theory and derive a minimum sample size for the spatially aggregated data. Only for the EKF computations, this minimum sample size is reached due to less variance of the ANN estimations. Generally, the EKF computation leads to a better ANN performance in contrast to LM. Finally, the spatial cross-submarket ANN estimation reaches accuracies of local property valuation procedures.;;https://doi.org/10.1016/j.landusepol.2021.105475;https://www.sciencedirect.com/science/article/pii/S0264837721001988;;;Real estate valuation, Artificial neural network, Complexity analysis, Adequate sample size;;0264-8377;;;
84;S;Impact of Categorical Variables Encoding on Property Mass Valuation;Sebastian Gnat;Procedia Computer Science;2021;Science@Direct;3542-3550;192;The main aim of the article was to present impact of categorical variables encoding on property mass valuation. Categorical variables are often used for describing important properties’ characteristics. In some countries, i.e., Poland, description of properties is mainly conducted with categorical variables, both nominal and ordinal. When property mass valuation is carried out it is important to introduce this kind of variables in best way to achieve most accurate results. There are many techniques of categorical variables encoding. In this study some of them were used in data pre-processing to determine whether the choice of encoding technique affects valuation results obtained with several regression algorithms. Three types of regression models were used in the research: a ridge regression model, k nearest neighbours regression and random forest regression algorithm. Each algorithm used explanatory variables coded using five techniques: one hot encoding, catboost encoding, Helmert encoding, target encoding and ordinal encoding. The results show that mass valuation results vary depending on how the encoding of categorical variables occurs. The regression algorithms used in the study respond differentially to the variable encoding techniques. Nevertheless, the one-hot encoding technique proved to be the best choice. The practical implications of the study are related to the reform of property taxation in Poland. Under this reform, values would become the basis for property taxation. This will be a complex undertaking, requiring the testing of various types of computational techniques to accurately determine the value of an enormous number of properties. The machine learning techniques presented in the study could be a part of a decision support system for introducing a new way of property taxation.;;https://doi.org/10.1016/j.procs.2021.09.127;https://www.sciencedirect.com/science/article/pii/S1877050921018664;;;categorical varibles encoding, property mass valuation, valuation accuracy;;1877-0509;;Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021;
85;S;Quality of life in Chinese cities;Tie Shi and Wenzhang Zhu and Shihe Fu;China Economic Review;2021;Science@Direct;101682;69;The Rosen-Roback spatial equilibrium theory states that cross-city variations in wages and housing prices reflect urban residents' willingness to pay for urban amenities or quality of life. This paper is the first to quantify and rank the quality of life in Chinese cities based on the Rosen-Roback model. Using the 2005 1% Population Intercensus Survey data, we estimate the wage and housing hedonic models. The coefficients of urban amenity variables in both hedonic models are considered the implicit prices of amenities and are used as the weights to compute the quality of life for each prefecture-level city in China. In general, provincial capital cities and cities with nice weather, good air quality, and accessible public transit have high quality of life. We also find that urban quality of life is positively associated with the subjective well-being of urban residents.;;https://doi.org/10.1016/j.chieco.2021.101682;https://www.sciencedirect.com/science/article/pii/S1043951X21001000;;;Spatial equilibrium, Hedonic model, Urban amenity, Quality of life, Life satisfaction;;1043-951X;;;
86;S;Machine learning models for credit analysis improvements: Predicting low-income families’ default;José Rômulo {de Castro Vieira} and Flavio Barboza and Vinicius Amorim Sobreiro and Herbert Kimura;Applied Soft Computing;2019;Science@Direct;105640;83;"The main objective of this study is to investigate the behaviour of default prediction models based on credit scoring methods and computational techniques with machine learning algorithms. The predictive capabilities of the models were compared to identify default-prediction mechanisms in the “My Home, My Life” Program (Programa “Minha Casa, Minha Vida” — PMCMV). The PMCMV is one of the largest government initiatives in the world to finance home ownership in the low-income population. Implemented by the Brazilian government, the programme has provided financing in excess of USD 84 billion and by 2016 had already contracted for the construction of over 4.5 million housing units, with 3.3 million units already delivered. The models developed in this study involve different time intervals for default prediction as well as analysis without the use of traditional discriminatory variables (gender, age, and marital status). Three measurements were used to evaluate the quality of the prediction models: area under the ROC curve, the Kolmogorov–Smirnov index, and the Brier score. The results indicated that (1) the accuracy of the models improves as the number of days overdue used to define the default variable increases; (2) the best prediction results were obtained with traditional ensemble techniques — in this case Bagging (BG), Random Forest (RF), and Boosting; and (3) there was a negative impact on all criteria when a smaller number of observations was used, especially on the type II error. It was also found that the discriminatory power of the credit risk rating system is preserved when removing discriminatory variables from the models. Applying the BG algorithm, which is the best prediction method, a default rate of 11.80% could be reduced to 2.95%, which leads to a selection that would result in 197,905 fewer delinquent contracts in the PMCMV, thus representing a savings of approximately USD 3.0 billion in credit losses.";;https://doi.org/10.1016/j.asoc.2019.105640;https://www.sciencedirect.com/science/article/pii/S156849461930420X;;;Low-income housing program, Credit risk, Default prediction, Machine learning, Predictive performance measures;;1568-4946;;;
87;S;Social media analytics: Extracting and visualizing Hilton hotel ratings and reviews from TripAdvisor;Yung-Chun Chang and Chih-Hao Ku and Chun-Hung Chen;International Journal of Information Management;2019;Science@Direct;263-279;48;Analyzing and extracting insights from user-generated data has become a topic of interest among businesses and research groups because such data contains valuable information, e.g., consumers’ opinions, ratings, and recommendations of products and services. However, the true value of social media data is rarely discovered due to overloaded information. Existing literature in analyzing online hotel reviews mainly focuses on a single data resource, lexicon, and analysis method and rarely provides marketing insights and decision-making information to improve business’ service and quality of products. We propose an integrated framework which includes a data crawler, data preprocessing, sentiment-sensitive tree construction, convolution tree kernel classification, aspect extraction and category detection, and visual analytics to gain insights into hotel ratings and reviews. The empirical findings show that our proposed approach outperforms baseline algorithms as well as well-known sentiment classification methods, and achieves high precision (0.95) and recall (0.96). The visual analytics results reveal that Business travelers tend to give lower ratings, while Couples tend to give higher ratings. In general, users tend to rate lowest in July and highest in December. The Business travelers more frequently use negative keywords, such as “rude,” “terrible,” “horrible,” “broken,” and “dirty,” to express their dissatisfied emotions toward their hotel stays in July.;;https://doi.org/10.1016/j.ijinfomgt.2017.11.001;https://www.sciencedirect.com/science/article/pii/S0268401217303389;;;Sentiment analysis, Hospitality, Natural language processing, Social media analytics, Visual analytics, Google trends, TripAdvisor;;0268-4012;;;
88;S;GeoGame analytics – A cyber-enabled petri dish for geographic modeling and simulation;Ola Ahlqvist and Nayan Khodke and Rajiv Ramnath;Computers, Environment and Urban Systems;2018;Science@Direct;1-8;67;As researchers start to conceptualize human-environmental interactions through coupled human and natural systems research, the non-linear, dynamic, heterogeneous, feedback loops that are characteristic of those systems challenges a long-standing Newtonian paradigm of systems reducible to component parts, deterministic behavior, and the existence of equilibrium. As an alternative, complex systems researchers often use agent-based models (ABM) or multi-agent systems (MAS) to model and simulate complexity in human-environmental interactions. This paper briefly reports on the development of a novel cyberinfrastructure portal solution called GeoGames. This computing environment integrates and leverages web-GIS and multiplayer online game technology to enable simulations of real-world scenarios of coupled human and natural systems applicable to anything from cities, urban regions to other human settlements. While there are some similarities between GeoGames and games like SimCity, and Civilization, a fundamental idea underlying the GeoGames approach is the focus on creating an on-line world that mirrors (c.f. Gelernter, 1991) authentic real-world geography, realized by a full range of GIS supported mapping and processing services (Ahlqvist, Loffing, Ramanathan, & Kocher, P). In the context of our prototype platform we present the emerging area of Spatial Game Analytics (Drachen & Schubert, 2013) that provides an uncharted area for data-intensive geospatial scenario analysis. Our example scenario is a game that models the relationships of land management on hydrology and water quality. Our presentation is illustrated with examples from our own prototype platform that has generated a significant amount of user data on game play decisions and behavior. Exploratory GeoGame analytics are used to mine the spatial behavior of hundreds of players in order to identify how variations in the rules (land use policies) and varying locations (spatial configurations) affect the simulation outcomes.;;https://doi.org/10.1016/j.compenvurbsys.2017.08.01;https://www.sciencedirect.com/science/article/pii/S0198971517304234;;;Games, Agent based models, Simulations, Analytics;;0198-9715;;;
89;S;Lean data: How small insights drive big data innovation;Sean R. McMahon;Organizational Dynamics;2019;Science@Direct;56-62;48;sinr;;https://doi.org/10.1016/j.orgdyn.2018.06.002;https://www.sciencedirect.com/science/article/pii/S009026161730267X;;;;;0090-2616;;;
90;S;Spatio-temporal stability of housing submarkets. Tracking spatial location of clusters of geographically weighted regression estimates of price determinants;Katarzyna Kopczewska and Piotr ?wiakowski;Land Use Policy;2021;Science@Direct;105292;103;This paper fills the gap in rich housing literature by testing the spatio-temporal stability of real estate submarkets. We start with standard Geographically Weighted Regression (GWR) estimation of the hedonic model on point data, and we cluster model coefficients to detect housing submarkets. We check spatio-temporal stability - we add novelty by comparing if clusters move over space or stay in the same place. We rasterise surface and apply the Rand Index and Jaccard Similarity to check if clusters assigned to raster cells yield stable spatial structure. This approach allows for quantitative assessments of how much determinants of price are stable over time and space. The same mechanism applied to standard errors of GWR coefficients is a good test of the spatio-temporal stability of local heteroscedasticity. A Case study of apartments' transactions in Warsaw-Poland for the 2006–2015 period, evidences relatively high spatio-temporal stability.;;https://doi.org/10.1016/j.landusepol.2021.105292;https://www.sciencedirect.com/science/article/pii/S0264837721000156;;;Geographically weighted regression, Spatio-temporal stability, Spatial location, Housing valuation, Submarkets, Data-driven clusters;;0264-8377;;;
91;S;Urban-rural disparities of household energy requirements and influence factors in China: Classification tree models;Guangwu Chen and Yuhan Zhu and Thomas Wiedmann and Lina Yao and Lixiao Xu and Yafei Wang;Applied Energy;2019;Science@Direct;1321-1335;250;The United Nations Sustainable Development Goals have highlighted the challenges brought about by increasing energy consumption and climate change. Previous studies have concentrated on accounting for urban and rural household energy requirements in China at a macro-scale, which neglects the analysis of individuals and their socio-economic driving factors at the micro-scale. To fill this gap, this study began with an accounting of energy requirements for urban and rural households based on the provincial Multi-Regional Input-Output (MRIO) tables and household survey covering over 25,000 unique samples from 25 provinces in 2012. Multilinear Regression models were employed to estimate the average effect of various demographic and socioeconomic characteristics of samples, and Tree-based models were applied to classify energy requirement groups and identify the key individual characteristics. The results suggest that the energy requirements per capita on average range from 34 to 211 GJ for urban samples and 34 to 149 GJ for rural samples across different provinces, and that the gap between individuals can be over 100 times. Indirect energy requirements representing above 90% of the total is the focus of the study. Changes in lifestyle factors include eating out, drinking and smoking, were all correlated with indirect energy requirements. Furthermore, the one-child family has had a positive effect on indirect energy requirements, while the two or more children family has had a negative effect. In addition, an individual’s mental health plays a role in the level of indirect energy requirements for high-income rural residents, while geographic location plays a key role for urban residents.;;https://doi.org/10.1016/j.apenergy.2019.04.170;https://www.sciencedirect.com/science/article/pii/S030626191930830X;;;Multiregional input-output model, Household energy requirements, Machine learning, Household survey;;0306-2619;;;
92;S;Lasso Penalty method for variable selection in database construction process and developing house value models in RUA;Iwona Fory?;Procedia Computer Science;2021;Science@Direct;3449-3456;192;The aim of this paper is to confirm that in the case of the analysis of large data sets, the Lasso Penalty Method (LASSO) gives better results in the process of eliminating variables for the purpose of real estate value models than classical methods such as Ridge Regression. The selection of variables for an econometric model is closely related to its quality and suitability for intelligent decision support systems applied in the processes of real estate value management in the vicinity of airports. Airports face huge compensation payments as a result of the negative noise externalities they generate for neighbouring properties. Both the scale and complexity of this phenomenon require the development of intelligent systems to support airport decisions on compensation management and to monitor the environmental effects of these decisions. The selection of variables describing property characteristics is the first step in building a cost-effective system, as many of these characteristics are qualitative in nature. While systems can feed spatial information and data available in official registers, qualitative data often requires individual assessments and field visits. Hence, assessing the suitability of a given piece of information for a model is crucial at the data collection stage, especially when long time series are being constructed. For this purpose, it is proposed to use LASSO and then to model the value of developments consisting of detached houses on sets of variables selected with this method. The results obtained for LASSO are promising. They give the best set of qualitative and quantitative explanatory variables. The method has less variability than other subset selection methods tested. LASSO reduces some coefficients and zeros others, while retaining the positive attributes of subset selection and ridge regression. Furthermore, LASSO performs variable selection and coefficient estimation simultaneously. In the perspective of large set formation, this method of variable selection can also be used in Data Mining methods for estimating the value of large sets of properties. The obtained results can successfully support the process of property value management in the vicinity of airports;;https://doi.org/10.1016/j.procs.2021.09.118;https://www.sciencedirect.com/science/article/pii/S1877050921018573;;;variable selection, lasso penatly method, house value, regression models;;1877-0509;;Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021;
93;S;A neural network and landscape metrics to propose a flexible urban growth boundary: A case study;Suman Chakraborti and Dipendra Nath Das and Biswajit Mondal and Hossein Shafizadeh-Moghadam and Yongjiu Feng;Ecological Indicators;2018;Science@Direct;952-965;93;Urban sprawl is a major barrier for the precise demarcation of administrative boundary in the world. In India, medium and small towns have so far developed outside the envisaged planning, resulting in a leapfrog and haphazard growth. This paper has attempted to simulate the spatial extent of urban expansion and boundary demarcation for the purpose of efficient urban planning and land resource management. An Artificial Neural Network (ANN) model and a set of landscape metrics were used to delineate the Urban Growth Boundary (UGB) and characterize the future patterns of growth in Siliguri Municipal Corporation (SMC, India). In particular, two urban boundaries – namely, Urban Hard Boundary (UHB) and Urban Soft Boundary (USB) – were simulated. The results suggest a USB with the area of 123?km2 to address the basic service delivery and a UHB with the area of 211.88?km2 to manage the ecological fragmentation.;;https://doi.org/10.1016/j.ecolind.2018.05.036;https://www.sciencedirect.com/science/article/pii/S1470160X18303777;;;Urban hard boundary, Urban soft boundary, Artificial neural network, Boundary demarcation, Landscape metrics;;1470-160X;;;
94;S;The language of neighborhoods: A predictive-analytical framework based on property advertisement text and mortgage lending data;Elizabeth C. Delmelle and Isabelle Nilsson;Computers, Environment and Urban Systems;2021;Science@Direct;101658;88;Real estate property listings use specific language to market properties to a target buyer – typically one that will garner the largest profit. As home-seekers have different preferences for house characteristics and neighborhood amenities, the words used to advertise homes are expected to vary according to the type of neighborhood and expected homebuyer. In this article, we develop a framework for extracting the key characteristics used to advertise properties according to the racial and income profile of home mortgage applicants in different types of neighborhoods. We perform an exploratory text analysis on words according to neighborhood types and use a binomial logistic regression model to determine the most discriminatory words for each type of neighborhood. Finally, we assess the ability of the property listing text to predict the type of neighborhood the property belongs to. Using a small, illustrative case study of listings from Charlotte, North Carolina, we find that the presence of specific neighborhood names holds more importance in neighborhoods with primarily White homebuyers. In gentrifying neighborhoods, unique property characteristics such as parquet flooring, and words associated with revitalization near the city center are common. Listings in neighborhoods with minority homebuyers are less likely to mention schools and feature traditionally suburban descriptors such as cars, garage, and roadways. We envision that this framework, using near real-time data sources, holds the potential to advance neighborhood prediction efforts, our understanding of amenity preferences and sorting patterns, and to illuminate less visible processes of change such as discrimination in the housing market.;;https://doi.org/10.1016/j.compenvurbsys.2021.10165;https://www.sciencedirect.com/science/article/pii/S019897152100065X;;;Text analysis, Real estate, Neighborhood typology;;0198-9715;;;
95;S;Social media big data and capital markets—An overview;Jaroslav Bukovina;Journal of Behavioral and Experimental Finance;2016;Science@Direct;18-26;11;A growing body of research and practical applications employ social media data as the proxy for a complex behavior of a society. This paper provides an overview of academic research related to a link between social media and capital markets. The theoretical rationale of this relationship is predominantly defined by behavioral finance. Behavioral finance augments the standard model of efficient markets and considers less rational factors like investors’ sentiment or public mood as influential for asset pricing and capital market volatility. In this context, social media is a novel tool enabling the collection of data about such less rational factors at the level of a society. The paper introduces social media data from a technical and economic point of view. In addition, it contributes to the theoretical construction of the transmission mechanism between social media and capital markets currently missing in the literature. Subsequently, the paper summarizes the main findings in this field and outlines future challenges in this research.;;https://doi.org/10.1016/j.jbef.2016.06.002;https://www.sciencedirect.com/science/article/pii/S2214635016300272;;;Social media, Retail investors, Information demand, Sentiment, Transmission mechanism;;2214-6350;;;
96;S;Predicting housing prices in China based on modified Holt's exponential smoothing incorporating whale optimization algorithm;Lianyi Liu and Lifeng Wu;Socio-Economic Planning Sciences;2020;Science@Direct;100916;72;The forecast of the real estate market is an important part of studying the Chinese economic market. Most existing methods have strict requirements on input variables and are complex in parameter estimation. To obtain better prediction results, a modified Holt's exponential smoothing (MHES) method was proposed to predict the housing price by using historical data. Unlike the traditional exponential smoothing models, MHES sets different weights on historical data and the smoothing parameters depend on the sample size. Meanwhile, the proposed MHES incorporates the whale optimization algorithm (WOA) to obtain the optimal parameters. Housing price data from Kunming, Changchun, Xuzhou and Handan were used to test the performance of the model. The housing prices results of four cities indicate that the proposed method has a smaller prediction error and shorter computation time than that of other traditional models. Therefore, WOA-MHES can be applied efficiently to housing price forecasting and can be a reliable tool for market investors and policy makers.;;https://doi.org/10.1016/j.seps.2020.100916;https://www.sciencedirect.com/science/article/pii/S0038012119306299;;;MHES, WOA, Housing prices, Predict, Time series;;0038-0121;;;
97;S;"{Modeling Housing Rent in the Atlanta Metropolitan Area Using Textual
Information and Deep Learning}";Zhou, Xiaolu and Tong, Weitian and Li, Dongying;{ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION};{2019};ISI Web of Science;;{8};"{The rental housing market plays a critical role in the United States
real estate market. In addition, rent changes are also indicators of
urban transformation and social phenomena. However, traditional data
sources for market rent prediction are often inaccurate or inadequate at
covering large geographies. With the development of housing information
exchange platforms such as Craigslist, user-generated rental listings
now provide big data that cover wide geographies and are rich in textual
information. Given the importance of rent prediction in urban studies,
this study aims to develop and evaluate models of rental market dynamics
using deep learning approaches on spatial and textual data from
Craigslist rental listings. We tested a number of machine learning and
deep learning models (e.g., convolutional neural network, recurrent
neural network) for the prediction of rental prices based on data
collected from Atlanta, GA, USA. With textual information alone, deep
learning models achieved an average root mean square error (RMSE) of
288.4 and mean absolute error (MAE) of 196.8. When combining textual
information with location and housing attributes, the integrated model
achieved an average RMSE of 227.9 and MAE of 145.4. These approaches can
be applied to assess the market value of rental properties, and the
prediction results can be used as indicators of a variety of urban
phenomena and provide practical references for home owners and renters.}";;{10.3390/ijgi8080349};;;;;;;;;
98;S;{Home Price Index: A Machine Learning Methodology};"Barr, Joseph R. and Ellis, Eden A. and Kassab, Antonio and Redfearn,
Christian L. and Srinivasan, Narayanan Nani and Voris, Kurtis B.";{INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING};{2017};ISI Web of Science;{111-133};{11};"{Estimating house prices is essential for homeowners and investors alike
with both needing to understand the value of their asset, and to
understand real estate assets as part of an overall portfolios.
Commonly-used indices like the National Association of Realtors (NAR)
median home price index, or the celebrated Case-Shiller Home Price Index
are reported exclusively over a large geographic areas, i.e., a
metropolitan, whereby home price dynamics are lost. In this paper, we
propose a improved method to capture price dynamics over time at the
most granular level possible - a single home. Using over 16 years of
home sale data, from the year 2000 to 2016, we estimate home price index
for each house. Once home price dynamics is captured, its possible to
aggregate price dynamics to construct a price index over geographies of
any kind, e.g., ZIP code. This particular index relies on a so-called
`gradient boosted' model, a methodology framework relying on multiple
calibration parameters and heavily dependent on sampling techniques. We
demonstrate that this approach offers several strengths compared to the
commonly reported indices, the `median sale' and `repeat sales' indices.}";;{10.1142/S1793351X17500015};;;;;;{1793-351X};;;
99;S;Image-Based Appraisal of Real Estate Properties;You, Quanzeng and Pang, Ran and Cao, Liangliang and Luo, Jiebo;IEEE Transactions on Multimedia;2017;IEEE Digital Library;2751-2759;19;Real estate appraisal, which is the process of estimating the price for real estate properties, is crucial for both buyers and sellers as the basis for negotiation and transaction. Traditionally, the repeat sales model has been widely adopted to estimate real estate prices. However, it depends on the design and calculation of a complex economic-related index, which is challenging to estimate accurately. Today, real estate brokers provide easy access to detailed online information on real estate properties to their clients. We are interested in estimating the real estate price from these large amounts of easily accessed data. In particular, we analyze the prediction power of online house pictures, which is one of the key factors for online users to make a potential visiting decision. The development of robust computer vision algorithms makes the analysis of visual content possible. In this paper, we employ a recurrent neural network to predict real estate prices using the state-of-the-art visual features. The experimental results indicate that our model outperforms several other state-of-the-art baseline algorithms in terms of both mean absolute error and mean absolute percentage error.;;10.1109/TMM.2017.2710804;;;;"Recurrent neural networks;Appraisal;Algorithm design and analysis;Prediction methods;Machine learning;Deep neural networks;real estate;visual content analysis";;1941-0077;;;
100;S;Deep Learning Model for House Price Prediction Using Heterogeneous Data Analysis Along With Joint Self-Attention Mechanism;Wang, Pei-Ying and Chen, Chiao-Ting and Su, Jain-Wun and Wang, Ting-Yun and Huang, Szu-Hao;IEEE Access;2021;IEEE Digital Library;55244-55259;9;House price prediction is a popular topic, and research teams are increasingly performing related studies by using deep learning or machine learning models. However, because some studies have not considered comprehensive information that affects house prices, prediction results are not always sufficiently precise. Therefore, we propose an end to end joint self-attention model for house prediction. In this model, we import data on public facilities such as parks, schools, and mass rapid transit stations to represent the availability of amenities, and we use satellite maps to analyze the environment surrounding houses. We adopt attention mechanisms, which are widely used in image, speech, and translation tasks, to identify crucial features that are considered by prospective house buyers. The model can automatically assign weights when given transaction data. Our proposed model differs from self-attention models because it considers the interaction between two different features to learn the complicated relationship between features in order to increase prediction precision. We conduct experiments to demonstrate the performance of the model. Experimental data include actual selling prices in real estate transaction data for the period from 2017 to 2018, public facility data acquired from the Taipei and New Taipei governments, and satellite maps crawled using the Google Maps application programming interface. We utilize these datasets to train our proposed and compare its performance with that of other machine learning-based models such as Extreme Gradient Boosting and Light Gradient Boosted Machine, deep learning, and several attention models. The experimental results indicate that the proposed model achieves a low prediction error and outperforms the other models. To the best of our knowledge, we are the first research to incorporate attention mechanism and STN network to conduct house price prediction.;;10.1109/ACCESS.2021.3071306;;;;"Hidden Markov models;Predictive models;Autoregressive processes;Biological system modeling;Satellites;Data models;Feature extraction;House price prediction;heterogeneous data;Google satellite map;spatial transformer network;joint self-attention mechanism";;2169-3536;;;
101;S;Can Web Search Queries Predict Prices Change on the Real Estate Market?;Rizun, Nina and Baj-Rogowska, Anna;IEEE Access;2021;IEEE Digital Library;70095-70117;9;"This study aims to explore whether the intensity of internet searches, according to the Google Trends search volume index (SVI), is a predictor of changes in real estate prices. The motivation of this study is the possibility to extend the understanding of the extra predictive power of Google search engine query volume of future housing price change (shift direction) by (i) the introduction of a research approach that combines the advantages of the complementary use of cross-correlation analysis and machine learning classification algorithms; (ii) applying the multi-class HPI values classifier which allows predicting the housing price increase, decrease or relative stability; (iii) exploiting the SVI that relates to interests in both `real estate' and `credit to buy real estate'; (iv) evaluation of the introduced approach in the context of the Polish real estate market. The main theoretical contribution of our work is a confirmation that the freely available information regarding Google user searches can provide an in-depth insight into enriching the generally accepted statistics on supply and demand in the real estate market. From the practical perspective, this research confirms that SVI can be associated as a sole determinant to anticipate the housing price change with time-lag sufficient for making decisions regarding the purchase (sale) of individual property or the real estate market control. Such findings can be also helpful for researchers who intend to use Google Trends data as an extra variable from demand side to improve the prediction accuracy if it is included in the model which is based on the existing housing prices determinants.";;10.1109/ACCESS.2021.3077860;;;;"Internet;Market research;Search engines;Predictive models;Cancer;Indexes;Forecasting;Big data utilization;cross-correlation analysis;machine learning classification;Google trends (GT);house price index (HPI);prediction;real estate market;search volume index (SVI);time-lag";;2169-3536;;;
102;S;A Machine Learning-Based Early Warning System for the Housing and Stock Markets;Park, Daehyeon and Ryu, Doojin;IEEE Access;2021;IEEE Digital Library;85566-85572;9;This study analyzes the relationship between the housing and stock markets, focusing on housing market bubbles. Stock market dynamics generally have a more significant impact on housing price movements than housing market dynamics have on stock dynamics. However, if housing market information is provided as a signal, housing price movements can predict stock market volatility. Accordingly, we build a machine learning-based early warning system (EWS) for the housing market using a long short-term memory (LSTM) neural network. Applying the generalized supremum augmented Dickey-Fuller test to extract the bubble signal in the housing market, we find that the signal simultaneously detects future changes in the housing market prices and future stock market volatility, and our EWS effectively detects the bubble signal. We confirm that the LSTM approach performs better than other benchmark models, the random forest and support vector machine models.;;10.1109/ACCESS.2021.3077962;;;;"Stock markets;Neural networks;Biological system modeling;Alarm systems;Predictive models;Mathematical model;Indexes;Early warning system;housing market bubble;long short-term memory;machine learning;stock market volatility";;2169-3536;;;
103;S;A neuro-advertising property video recommendation system;A. Kaklauskas and E.K. Zavadskas and A. Banaitis and I. Meidute-Kavaliauskiene and A. Liberman and S. Dzitac and I. Ubarte and A. Binkyte and J. Cerkauskas and A. Kuzminske and A. Naumcik;Technological Forecasting and Social Change;2018;El Compendex;78-93;131;Many factors influence the identification of the best real estate alternatives, such as supply and demand and the social, cultural, psychological and personal factors affecting buyer behavior and the emotional state of a buyer. What are the most effective ways of choosing a property, when the selection is so vast and complex? An aid is developed here to accomplish this, based on a new advertising format, an iterative method and the NEuro-Advertising Property Video Recommendation System (NEAR). A known methodology involves behavioral operational research and the emotions involved in decision-making. Three advanced research contributions are unique to the proposed method and NEAR, in contrast to innovative behavioral operational research. Firstly, data are compiled for a neuro decision matrix, based on housing attributes and the valence, arousal, emotional state and physiological parameters of a potential real estate buyer. Secondly, the performance of a multiple criteria neuroanalysis occurs as well as the selection of the most personalized and effective video clip ad variants drawn from many alternatives. Finally, NEAR is found to present the most effective video clips ads for real estate buyers for as long a period as possible, according to Multiple Resource Theory.;;https://doi.org/10.1016/j.techfore.2017.07.011;https://www.sciencedirect.com/science/article/pii/S0040162517309332;;;MCDA, Property, Methods, Neuro decision matrix, Affective computing, Knowledge-based real-world applications;;0040-1625;;;
104;S;Forecasting house-price growth in the Euro area with dynamic model averaging;Marian Risse and Martin Kern;The North American Journal of Economics and Finance;2016;El Compendex;70-85;38;We use a dynamic modeling and selection approach for studying the informational content of various macroeconomic, monetary, and demographic fundamentals for forecasting house-price growth in the six largest countries of the European Monetary Union. The approach accounts for model uncertainty and model instability. We find superior performance compared to various alternative forecasting models. Plots of cumulative forecast errors visualize the superior performance of our approach, particularly after the recent financial crisis.;;https://doi.org/10.1016/j.najef.2016.08.001;https://www.sciencedirect.com/science/article/pii/S1062940816300730;;;House prices, Dynamic model averaging, Forecasting, Europe;;1062-9408;;;
105;S;Mapping the fine-scale spatial pattern of housing rent in the metropolitan area by using online rental listings and ensemble learning;Yimin Chen and Xiaoping Liu and Xia Li and Yilun Liu and Xiaocong Xu;Applied Geography;2016;El Compendex;200-212;75;"Abstracts
The accurate mapping of housing rent is crucial to the understanding of residential dynamics. In this study, we proposed the use of online rental listings as a new reliable data source for mapping housing rent. With the collected individual rental information from an online platform, we attempted to produce the fine-scale spatial pattern of housing rent in the metropolitan area of Guangzhou, China, at the neighborhood committee (NC) level. This involves the task of estimating the housing rent for areas with no observation data of housing rent. To this end, we evaluated six numeric prediction methods of machine learning. We further enhanced their performance through ensemble learning, an approach which can form new classifiers with even better performance than any of the individual constituent classifiers. We implemented ensemble learning through ways of bagging and stacking, and selected the most accurate ensemble classifier to produce the spatial pattern of housing rent at the NC-level. In the resulting housing rent pattern, we identified a distance decay relationship between the housing rent and the distance from the city center. The data sources and the ensemble learning platform in this application of housing rent mapping are generally open access. Therefore, the proposed approach in this study can provide useful hints for housing rent mapping in other geographical areas. Our mapping results can also be integrated with additional information to support the studies of urban residential problems in China.";;https://doi.org/10.1016/j.apgeog.2016.08.011;https://www.sciencedirect.com/science/article/pii/S0143622816303204;;;Housing rent mapping, Online rental listings, Anjuke, Ensemble learning;;0143-6228;;;
106;S;An empirical comparison of classification algorithms for mortgage default prediction: evidence from a distressed mortgage market;Trevor Fitzpatrick and Christophe Mues;European Journal of Operational Research;2016;El Compendex;427-439;249;This paper evaluates the performance of a number of modelling approaches for future mortgage default status. Boosted regression trees, random forests, penalised linear and semi-parametric logistic regression models are applied to four portfolios of over 300,000 Irish owner-occupier mortgages. The main findings are that the selected approaches have varying degrees of predictive power and that boosted regression trees significantly outperform logistic regression. This suggests that boosted regression trees can be a useful addition to the current toolkit for mortgage credit risk assessment by banks and regulators.;;https://doi.org/10.1016/j.ejor.2015.09.014;https://www.sciencedirect.com/science/article/pii/S0377221715008383;;;Boosting, Random forests, Semi-parametric models, Mortgages, Credit scoring;;0377-2217;;;
107;S;The range of uncertainty on the property market pricing: The case of the city of Shanghai;Jian Zhou and Yixuan Shen and Athanasios A. Pantelous and Hui Zhang;Finance Research Letters;2021;El Compendex;101720;40;Property prices around the globe have seen very strong growth over the last two decades. Across various advanced countries, such a rapid and uncontrolled growth in house prices puts their economy in danger, and most importantly, their social integration and interconnectedness at great risk. In this paper, we develop a novel fuzzy linear regression framework using symmetric and asymmetric trapezoidal fuzzy numbers for determining the relationship of particular (non-) policy factors with the house prices. An interviewing questionnaire survey was conducted for collecting real data for the city of Shanghai to illustrate our theoretical treatment.;;https://doi.org/10.1016/j.frl.2020.101720;https://www.sciencedirect.com/science/article/pii/S1544612320309697;;;House prices, Bid-Ask spread, Fuzzy linear regression, Trapezoidal fuzzy numbers;;1544-6123;;;
108;S;A systematic review of big data-based urban sustainability research: State-of-the-science and future directions;Lingqiang Kong and Zhifeng Liu and Jianguo Wu;Journal of Cleaner Production;2020;El Compendex;123142;273;The future of humanity depends increasingly on the performance of cities. Big data provide new and powerful ways of studying and improving coupled urban environmental, social, and economic systems to achieve urban sustainability. However, the term big data has been defined variably, and its urban applications have so far been sporadic in terms of research topic and location. A comprehensive review of big data-based urban environment, society, and sustainability (UESS) research is much needed. The aim of this study was to summarize the big data-based UESS research using a systematic review approach in combination with bibliometric and thematic analyses. The results showed that the numbers of publications and citations of related articles have been increasing exponentially in recent years. The most frequently used big data in UESS research are human behavior data, and the major analytical methods are of five types: classification, clustering, regression, association rules, and social network analysis. The major research topics of big data-based UESS research include urban mobility, urban land use and planning, environmental sustainability, public health and safety, social equity, tourism, resources and energy utilization, real estate, and retail, accommodation and catering. Big data benefit UESS research by proving a people-oriented perspective, timely and real-time information, and fine-resolution spatial dynamics. In addition, several obstacles were identified to applying big data in UESS research, which are related to data quality and acquisition, data storage and management, data security and privacy, data cleaning and preprocessing, and data analysis and information mining. To move forward, future research should integrate multiple big data sources, develop and utilize new methods such as deep learning and cloud computing, and expand the application fields to focus on the interactions between human activities and urban environments. This review can contribute to understanding the current situation of big data-based UESS research, and provide a reference for studies of this topic in the future.;;https://doi.org/10.1016/j.jclepro.2020.123142;https://www.sciencedirect.com/science/article/pii/S0959652620331875;;;Big data, Social media data, Urban landscape sustainability, Smart city, Urban planning;;0959-6526;;;
109;S;Enhancing the passive design of buildings: A mixed integer non-linear programming approach for the selection of building materials and construction building systems;Ahmed W.A. Hammad and Karoline Figueiredo and Ana Carolina Rosa and Elaine Vazquez and Assed Haddad;Energy Reports;2021;El Compendex;;;Consumption of energy in buildings accounts for a considerable proportion of worldwide energy use. There is a dire need for enhancing the energy efficiency of building to limit their demand for operating energy as this leads to enhanced reductions in environmental impacts. Of particular relevance to the amount of energy utilised in a building during the operation phase is the nature of material and size of components utilised in the building. In this work, a mathematical programming framework is presented to optimise a number of building design objective functions, including heat gain, daylight and economic cost of material utilised. The variables that are focussed on in this study are the sizes of windows, type of material adopted for the building, embodied in the construction building systems used for various building components, and the type of lighting adopted. To validate the framework, two realistic case studies obtained from an industry partner are adopted and solved via the use of the proposed mathematical programming method. Results indicate that compared to the solutions proposed by an experienced engineer, the daylight, heating and cost of the building is enhanced by up to 39%, 43% and 23% respectively. The framework is hoped to help policy makers introduce more streamlined guidance for the building sector when it comes to optimised material choice and window sizing to result in energy-efficient and economical buildings.;;https://doi.org/10.1016/j.egyr.2021.04.063;https://www.sciencedirect.com/science/article/pii/S2352484721003747;;;Energy efficiency, Heat gain, Daylight, Building materials, Multi-objective optimisation, MINLP;;2352-4847;;;
110;S;Does my house have a premium or discount in relation to my neighbors? A regression-kriging approach;Jorge Chica-Olmo and Rafael Cano-Guervos;Socio-Economic Planning Sciences;2020;El Compendex;100914;72;In the real estate literature, numerous studies have applied hedonic models to estimate the implicit value of the characteristics that influence housing prices. However, few studies have quantified the weight of location in the price of residential properties, and still fewer have quantified the premium or discount used to weigh the price of a home. In this paper, the regression-kriging method is applied to address the two previous objectives in the city of Granada, Spain. This method is also adapted, interpreted and made accessible to real estate appraisers with a view to providing these professionals with an objective, sophisticated and powerful tool in accordance with their know-how. This method can also be useful for investors, urban planners, public administrators and revenue departments, among others, as it can determine the value distribution of the location.;;https://doi.org/10.1016/j.seps.2020.100914;https://www.sciencedirect.com/science/article/pii/S0038012119305233;;;Location, Housing prices, Real estate, Premium and discount, Regression-kriging;;0038-0121;;;
111;S;A System Dynamics Approach for Study of Population Growth and The Residential Housing Market in the US;Gasser Galal Ali and Islam H. El-Adaway and Cihan H. Dagli;Procedia Computer Science;2020;El Compendex;154-160;168;The US Consensus bureau estimated the total construction spending at 1,320,305 Million Dollars, in February 2020, with an increase of 1.1% since last February. The construction market is large, and risky. Prediction of the market behavior, for several years ahead, is needed in order to take strategic investment decision for long and expensive projects. The goal of this research is to study the relationship between population growth and the housing market. To that end, a system dynamics model is developed. System dynamics is a top-down approach that starts with the high-level behavior of a complex system to simulate the behavior of that system over time. The developed model simulates the housing market by matching the population growth with the housing demand in monthly time steps. As such, the parameters of the developed model include birth rate, life expectancy, immigration, emigration, and construction seasonality. Using these parameters, the model simulates the population size and demand for housing. For validation, the outputs of the model are compared with real-life data for the US. When complete, the model should assist market researchers in simulating the housing market. This research benefits large real estate developers, construction companies, governmental and financial agencies.;;https://doi.org/10.1016/j.procs.2020.02.281;https://www.sciencedirect.com/science/article/pii/S1877050920304208;;;Complex Systems, System Dynamics, Simulation, Housing, Construction;;1877-0509;;“Complex Adaptive Systems”Malvern, PennsylvaniaNovember 13-15, 2019;
112;S;A comparison of the approaches for gentrification identification;Cheng Liu and Yu Deng and Weixuan Song and Qiyan Wu and Jian Gong;Cities;2019;El Compendex;102482;95;Gentrification can be identified via a threshold-based method and/or a machine-learning approach. The former, which is simple and theoretically sound, is complementary to the latter, which is objective. In view of a lack of research on exploiting the strengths of both approaches, this study compares a threshold-based method to K -means clustering. Using the city of Auckland as a case study, we find that both approaches are in accord with each other. The maximum degrees of similarity (falling in the range 0–1) between the identification results of both approaches are 0.80 and 0.56 for binary and three-level identification, respectively. By comparison, it is evident that the threshold-based set of identification rules delineates gentrification more accurately. For example, a census tract with a confluence of housing reinvestment and at least one aspect of social upgrading is more likely to be identified as gentrified. Moreover, gentrification in Auckland assumes various appearances. Retaining a simple and universal conceptual and analytical framework for gentrification helps us focus on the essentials of this urban phenomenon: reinvestment and displacement.;;https://doi.org/10.1016/j.cities.2019.102482;https://www.sciencedirect.com/science/article/pii/S0264275118315440;;;Gentrification identification, Threshold, -means clustering, Housing reinvestment, Displacement;;0264-2751;;;
113;S;Mapping inclusive innovation: A bibliometric study and literature review;Sina Mortazavi and Mohammad H. Eslami and Arash Hajikhani and Juha Väätänen;Journal of Business Research;2021;El Compendex;736-750;122;Inclusive innovation is a type of innovation that targets not only affordability but also localization of underdeveloped countries, with the aim of reducing poverty. Despite the increasing attention paid to inclusive innovation, there is no common understanding of how the inclusive innovation notion is formed among researchers and experts. This study adopts a novel approach by combining bibliometric methods of co-citation analysis and text codifying of 293 core and relevant journal articles on inclusive innovation. The results reveal that the notion of inclusive innovation has evolved in five clusters: (1) innovation as a tool for affordability, (2) innovation as a tool for inclusion, (3) building of capabilities and innovation, (4) innovation constraints associated with social empowerment, and (5) innovation as an inclusive system. Furthermore, this study proposes a conceptual model based on these clusters, and discusses the nature of how these clusters lead to the possibility for further studies on inclusive innovation.;;https://doi.org/10.1016/j.jbusres.2020.07.030;https://www.sciencedirect.com/science/article/pii/S0148296320304641;;;Inclusive innovation, Bibliometric analysis, Base of the pyramid, Social empowerment;;0148-2963;;;
114;S;Determining heterogeneity of residential location preferences of households in Belgium;Kasper Cockx and Frank Canters;Applied Geography;2020;El Compendex;102271;124;Residential location choice behaviour is a key component of the complex and dynamic human-environment interactions driving changes in the urban landscape. The residential location choices that households make depend on their socio-economic characteristics, attitudes and life cycle stage as well as the location's properties. The objective of this research was to analyse residential location preferences for different types of households in Belgium by developing a residential location choice model based on the use of regression trees. For each preference group, a discrete choice model was estimated identifying the main factors influencing residential location choices, and how these differ depending on household characteristics. The data-driven approach proposed in this paper enables a transparent interpretation of the main household characteristics explaining differences in residential location choice behaviour, and of the varying effect of location characteristics on residential location choice. Results obtained with the model show that tenure status, education level, nationality and household type successfully discriminate heterogeneous residential location preference profiles in Belgium. Model variables for each preference group demonstrate that not only socio-economic characteristics of the resident population, but also housing price and job accessibility differentially affect a location's attractivity for different household profiles.;;https://doi.org/10.1016/j.apgeog.2020.102271;https://www.sciencedirect.com/science/article/pii/S0143622819301298;;;Residential location choice, Preference heterogeneity, Households, Discrete choice modeling, Segmentation;;0143-6228;;;
115;S;Spatiotemporal analysis of the housing bubble's contribution to the proliferation of illegal landfills – The case of Gran Canaria;Lorenzo Carlos Quesada-Ruiz and Liliana Perez and Victor Rodriguez-Galiano;Science of The Total Environment;2019;El Compendex;104-117;687;Illegal landfills are the source of many impacts that can alter the environment and represent a public health risk. This study investigates their spatiotemporal distribution in two representative areas of Gran Canaria: northwest (Zone A) and east (Zone B). Illegal landfill occurrence was simulated between 2000 and 2018, to estimate and spatially locate the surface growth of illegal landfills based on cellular automata, cellular automata-Markov and multiobjective land allocation models. The proliferation of illegal landfills in 2018 was simulated following the calibration and validation of the proposed models. Models' accuracy was assessed using Kappa index and landscape metrics. The cellular automata-Markov model had the best performance. The model simulations predicted an increase of 52.3?ha and 81.5?ha affected by illegal landfills in Zone A and Zone B for 2018, respectively. The interannual growth rate of surfaces affected by illegal landfills for the period between 2000 and 2006 was 4.5% and 9.5% and between 2006 and 2012 it was 6.6% and 6.7%, for Zone A and Zone B respectively. The growth of illegal landfills between 2000 and 2006 was higher in urban areas, construction sites, and industrial zones, and may be closely related to the process of urban expansion linked to the real estate boom. The latter would have a deep impact on the landscape due to the proliferation of illegal construction and demolition waste. The growth rate of illegal landfills in urban environments fell during the later period of urban expansion. Overall, simulation outputs showed the model's ability to correctly reproduce the distribution patterns for illegal landfill proliferation. Even though the simulated spatial location of illegal landfills was not highly accurate, the models built in this study provide an informative tool to policy makers to aid the process creating policies for environmental protection as well as territorial planning.;;https://doi.org/10.1016/j.scitotenv.2019.06.079;https://www.sciencedirect.com/science/article/pii/S0048969719326476;;;Cellular automata, Logistic regression, Markov models, Land change modelling, Illegal landfill occurrence;;0048-9697;;;
116;S;Monitoring housing rental prices based on social media:An integrated approach of machine-learning algorithms and hedonic modeling to inform equitable housing policies;Lirong Hu and Shenjing He and Zixuan Han and He Xiao and Shiliang Su and Min Weng and Zhongliang Cai;Land Use Policy;2019;El Compendex;657-673;82;National land use policies and strategies worldwide have attempted to establish a healthy housing rental market towards urban sustainability. Monitoring fine-scale housing rental prices should provide essential implications for equitable housing policies. However, doing so remains a challenge because aggregated data were traditionally collected at a coarse scale through census or social surveys. On-line housing rental websites (OHRWs) have become popular social media platforms in the housing studies. This paper attempts to demonstrate how to monitor fine-scale housing rental prices based on OHRWs using the case of Shenzhen in China. Employing hedonic model, a set of housing rental determinants are initially selected from three characteristics (neighborhood, location and structure) and at three levels (nearest accessibility, 15-minute walking distance availability and sub-district availability). Housing rent prediction models are then established (respectively for October 2017 and February 2018) using the training samples collected from the OHRWs and six machine-learning algorithms, including random forest regression (RFR), extra-trees regression (ETR), gradient-boosting regression (GBR), support vector regression (SVR), multi-layer perceptron neural network (MLP-NN) and k-nearest neighbor algorithm (k-NN). Thereafter, the relative importance of the determinants is calculated and visualized using partial dependence plots. Finally, the models are used to monitor housing rental price dynamics for all of the communities within Shenzhen. Results show that all of the algorithms except SVR generally present good performance. Among them, RFR and ETR are the best one in October 2017 and February 2018, respectively. Concerning the spatial pattern of housing rental, the high-high clusters merge in the central districts, whereas the low-low clusters are located in the outskirts, and the growth rate is the greatest in the farthest outskirts from the central districts. Each determinant affects the housing rent across different scale and sub-district availability and nearest accessibility are more important than 15-minute walking distance availability. The two most influential determinants are sub-district job opportunity and nearest accessibility to health care facilities. The case of Shenzhen shows that the demonstrated framework, which integrates machine-learning algorithms and the hedonic modeling, is practical and efficient. The approach is believed to provide an essential tool to inform equitable housing policies.;;https://doi.org/10.1016/j.landusepol.2018.12.030;https://www.sciencedirect.com/science/article/pii/S0264837718316429;;;Housing rental price, Social media, Hedonic model, Multilevel determinants, Machine learning, Equitable housing policies;;0264-8377;;;
117;S;Automated design and modeling for mass-customized housing. A web-based design space catalog for timber structures;Fabio Bianconi and Marco Filippucci and Alessandro Buffi;Automation in Construction;2019;El Compendex;13-25;103;The research proposes a model for mass-customized housing in the emerging context of Industry 4.0 promoted by the European Union as a mean for technological and industrial innovation. With the aim to develop a cross-laminated timber (CLT) model for the Architecture, Engineering, and Construction (AEC) industry, the study deepens the possibility of using generative models and evolutionary principles to inform the customization process in the early stage of design. By trying to bring the latest innovation in the field of computer science and information technology to customers who typically are not proficient with algorithmic design and computation, the research builds up an intuitive interface that allows customers to explore different design solutions. Related to the scale of a single-family house, this model is intended to be used as a decision support system for the design of residential and emergency homes in central Italy.;;https://doi.org/10.1016/j.autcon.2019.03.002;https://www.sciencedirect.com/science/article/pii/S0926580518305302;;;Mass-customization, Design automation, Timber construction, Multi-objective optimization, Parametric design, Genetic Algorithms (GA), Building Information Modeling (BIM), Energy optimization, Hyperdimensional data analysis, Data driven design;;0926-5805;;;
118;S;A BIM and machine learning integration framework for automated property valuation;Tengxiang Su and Haijiang Li and Yi An;Journal of Building Engineering;2021;El Compendex;102636;44;Property valuation contributes significantly to market economic activities, while it has been continuously questioned on its low transparency, inaccuracy and inefficiency. With Big Data applications in real estate domain growing fast, computer-aided valuation systems such as AI-enhanced automated valuation models (AVMs) have the potential to address these issues. While a plethora of research has focused on improving predictive performance of AVMs, little effort has been made on information requirements for valuation models. As the amount of data in BIM is rising exponentially, the value-relevant design information has not been widely utilized for property valuation. This paper presents a system that leverages a holistic data interpretation, improves information exchange between AEC projects and property valuation, and automates specific workflows for property valuation. A mixed research method was adopted combining the archival literature research, qualitative and quantitative data analysis. A BIM and Machine learning (ML) integration framework for automated property valuation was proposed which contains a fundamental database interpretation, an IFC-based information extraction and an automated valuation model based on genetic algorithm optimized machine learning (GA-GBR). The main findings indicated: (1) Partial information requirements can be extracted from BIM models, (2) Property valuation can be performed in a more accurate and efficient way. This research contributes to managing information exchange between AEC projects and property valuation and supporting automated property valuation. It was suggested that the infusion of BIM, ML and other emerging digital technologies might add values to property valuation and the construction industry.;;https://doi.org/10.1016/j.jobe.2021.102636;https://www.sciencedirect.com/science/article/pii/S2352710221004940;;;Property valuation, Information exchange, Building information modelling (BIM), Industry foundation class (IFC), Machine learning (ML);;2352-7102;;;
119;S;Treatment of the Airbnb controversy by the press;Assumpció Huertas and Berta Ferrer-Rosell and Estela Marine-Roig and Eduard Cristobal-Fransi;International Journal of Hospitality Management;2021;El Compendex;102762;95;Airbnb is one of the most transformative developments in the traditional accommodation system. Due to the social impact it entails, Airbnb is currently a present topic in the press, although studies on how Airbnb is treated in the press are very scarce. Thus, this article aims to analyse the treatment of Airbnb controversial issues in the press and its evolution. The analysis method is first to follow the evolution from 2016 to 2018, second, to conduct a computerised quantitative content analysis, and finally to analyse the importance of information published through compositional data analysis. Results show that topics appearing most in the news are legal issues and regulations followed by gentrification, new forms of tourism and sharing economy, mainly being treated from a negative perspective, although are evolving towards a more positive vision. Results can be useful for local and national authorities to understand and manage this phenomenon.;;https://doi.org/10.1016/j.ijhm.2020.102762;https://www.sciencedirect.com/science/article/pii/S0278431920303145;;;Compositional data analysis, Accommodation sharing, Media, Content analysis, Controversial issues, Airbnb;;0278-4319;;;
120;S;Measuring aggregate housing wealth: New insights from machine learning ?;Joshua Gallin and Raven Molloy and Eric Nielsen and Paul Smith and Kamila Sommer;Journal of Housing Economics;2021;El Compendex;101734;51;We construct a new measure of aggregate housing wealth for the U.S. based on (1) home-value estimates derived from machine learning algorithms applied to detailed information on property characteristics and recent transaction prices, and (2) Census housing unit counts. According to our new measure, the timing and amplitude of the recent house-price cycle differs materially but plausibly from commonly-used measures, which are based on survey data or repeat-sales price indexes. Thus, our methodology generates estimates that should be of considerable value to researchers and policymakers interested in the dynamics of aggregate housing wealth.;;https://doi.org/10.1016/j.jhe.2020.101734;https://www.sciencedirect.com/science/article/pii/S105113772030070X;;;Residential real estate, Consumer economics and finance, Data collection and estimation, Flow of funds;;1051-1377;;;
121;S;Creating spatially-detailed heterogeneous synthetic populations for agent-based microsimulation;Meng Zhou and Jason Li and Rounaq Basu and Joseph Ferreira;Computers, Environment and Urban Systems;2022;El Compendex;101717;91;Agent-based models (ABMs) of urban systems have grown in popularity and complexity due to the widespread availability of high-performance computing resources and large data storage capabilities. Credible synthetic populations are crucial for the application of ABMs to understand urban phenomena. Although several (agent) population synthesis methods have been suggested over the years, the spatial dimension of synthetic populations has not received as much attention. This study addresses this myopic treatment of synthetic populations by creating two distinct components – agents and the built environment – that are integrated to form a ‘full’ spatially-detailed synthetic population. To generate agents, we used multiple Bayesian Networks (BN) to probabilistically draw pools from the microsample, followed by a Generalized Raking (GR) adjustment to match marginal controls. Using various measures, we demonstrate that our BN+GR framework outperforms more commonly used synthesis methods in both capturing the heterogeneity in the microsample and matching marginal controls. We also highlight the importance of accounting for heterogeneity by using separate type-specific models based on an explicitly defined household typology. For built environment synthesis, we generated various spatial entities such as buildings, housing units, establishments, and jobs at distinct spatial locations by fusing data from various spatial datasets. Their spatial distributions are found to effectively approximate the ‘real’ built environment in our study area. Our proposed framework can be used to generate a ‘full’ synthetic population for use in ABMs with more spatio-demographic heterogeneity than can otherwise be estimated using traditional methods.;;https://doi.org/10.1016/j.compenvurbsys.2021.10171;https://www.sciencedirect.com/science/article/pii/S0198971521001241;;;Synthetic population, Built environment, Agent-based microsimulation, Bayesian Network, Land use-transport interaction (LUTI) model;;0198-9715;;;
122;S;House style recognition using deep convolutional neural network;Yun Kyu Yi and Yahan Zhang and Junyoung Myung;Automation in Construction;2020;El Compendex;103307;118;The recent development in deep learning has opened up a new era of possibilities, once difficult to achieve with conventional methods, to revolutionize image recognition, speech recognition, and natural language processing. Specifically, image recognition has been widely applied in various areas such as face recognition, object identification for security, and other purposes. Although it is rarely applied to discover new methods for use in architecture, image recognition has great potential in architectural design. For example, it can be used to identify the preference of the client and to design a building that satisfies a client's aesthetic preference. One of the major hurdles of utilizing image recognition in architecture is the architectural styles based on culture, location, and time. For that reason, it is difficult to identify an architectural style by non-trained clients and sometimes certain buildings are composed of different styles that are difficult to identify by experts as one style. This paper explores the possibility of using state-of-the-art image recognition algorithms in house style recognition to find out its limitations and possibilities. Moreover, the paper adopted a convolutional neural network model for classifying house styles in the US. Although the final accuracy is not high due to the lack of image datasets, the trained model performed reasonable predictions with a limited test set. The results show the importance of properly defining style for image recognition to improve its accuracy.;;https://doi.org/10.1016/j.autcon.2020.103307;https://www.sciencedirect.com/science/article/pii/S0926580520300261;;;House style, Image recognition, Deep Convolutional Neural Network (DCNN), Deep learning;;0926-5805;;;
123;S;Information value of property description: A Machine learning approach;Lily Shen and Stephen Ross;Journal of Urban Economics;2021;El Compendex;103299;121;This paper employs machine learning to quantify the value of “soft” information contained in real estate property descriptions. Textual descriptions contain information that traditional hedonic attributes cannot capture. A one standard deviation increase in the uniqueness of a property based on this “soft” information leads to a 15% increase in property sale price in a hedonic price model and a 10% increase in a repeat sales price model. The effects in the hedonic model appear to arise through two channels: the unobserved quality of the housing unit, and the market power of the housing unit relative to competing properties. The effects in the repeat sales model appear to be driven entirely by the market power of the unit. Further, an annual hedonic price index ignoring our measure of unobserved quality overstates real estate prices by between 10% to 23% and mistimes the stabilization of housing prices following the Great Recession. Similar, but smaller effects, are observed for the repeat sales price index.;;https://doi.org/10.1016/j.jue.2020.103299;https://www.sciencedirect.com/science/article/pii/S009411902030070X;;;Natural language processing, Unsupervised machine learning, Soft information, Housing prices, Price indexes, Property descriptions;;0094-1190;;;
124;S;Human settlement value assessment from a place perspective: Considering human dynamics and perceptions in house price modeling;Yuhao Kang and Fan Zhang and Song Gao and Wenzhe Peng and Carlo Ratti;Cities;2021;El Compendex;103333;118;A better formalization of place - where people live, perceive, and interact with others - is crucial for understanding socioeconomic environment and human settlement. The widely used hedonic pricing model for houses was proposed from the perspective of space, focusing mostly on static house structural information and objective built environment factors. However, the value of house settlement is not only determined by its spatial settings, but also varies from one place to another with different cultures, human dynamics, human perceptions and social interactions. In this work, we introduce a place-oriented hedonic pricing model (P-HPM) that incorporates human dynamics and human perceptions of places to understand human settlement. As an empirical study, we employ a large volume of house price data in Boston and Los Angeles, including detailed house and locational amenity information. Besides, we take the hourly number of visits to places as a proxy of human mobility patterns, and obtain human perceptions of places extracted from large-scale street-view images using deep learning. The results show that the P-HPM outperformed the traditional HPM significantly in these two cities. Moreover, through a geographically weighted regression analysis and the Monte Carlo test, we find that the impacts of the proposed place-related variables on house prices are stable across space. Our results provide new insights into the assessment of human settlement values by incorporating the role of place using multi-source big geo-data.;;https://doi.org/10.1016/j.cities.2021.103333;https://www.sciencedirect.com/science/article/pii/S026427512100233X;;;Hedonic pricing model, Human dynamics, Human perception, Street-view images, Sense of place, GeoAI;;0264-2751;;;
125;S;Macroeconomic indicators alone can predict the monthly closing price of major U.S. indices: Insights from artificial intelligence, time-series analysis and hybrid models;Bin Weng and Waldyn Martinez and Yao-Te Tsai and Chen Li and Lin Lu and James R. Barth and Fadel M. Megahed;Applied Soft Computing;2018;El Compendex;685-697;71;This paper proposes a two-stage approach that can be used to investigate whether the information hidden in macroeconomic variables (alone) can be used to accurately predict the one-month ahead price for major U.S stock and sector indices. Stage 1 is constructed to evaluate the hypothesis that the price for different indices is driven by different economic indicators. It consists of three phases. In phase I, the data is automatically acquired using freely available APIs (application programming interfaces) and prepared for analysis. Phase II reduces the set of potential predictors without the loss of information through several variable selection methods. The third phase employs four ensemble models and three time-series models for prediction. The prediction performance of the seven models are compared using the Mean Absolute Percent Error (and two additional metrics). If the hypothesis were to be true, one expects that the performance of the ensemble models to outperform the time-series models since the information in the economy is more important than the information in previous prices. In Stage 2, a hybrid approach of the recurring neural network used for time-series prediction (i.e., the LSTM) and the ensemble models is constructed to examine the secondary hypothesis that the residuals from the time-series models are not random and can be explained by the macroeconomic indicators. To test the two hypotheses, the monthly closing prices for 13 U.S. stock and sector indices and the corresponding values for 23 macroeconomic indicators were collected from 01/1992–10/2016. Based on the case study, the four ensembles prediction performance were superior to that of the three time-series models. The MAPE of the best model for a given index was < 1.87%. The Stage 2 results also show that the three evaluation metrics (RMSE, MAPE and MAE) can be typically improved by 25–50% by incorporating the information hidden in the macroeconomic indicators (through the ensemble approach). Thus, this paper shows that, for the analysis period and the indices studied, the macro-economic indicators are leading predictors of the price of 13 U.S. sector indices.;;https://doi.org/10.1016/j.asoc.2018.07.024;https://www.sciencedirect.com/science/article/pii/S1568494618304125;;;ARIMA, Deep learning, Ensembles, GARCH, Long short-term memory (LSTM) networks;;1568-4946;;;
126;S;Machine learning with explainability or spatial hedonics tools? An analysis of the asking prices in the housing market in Alicante, Spain;Juan Ramón Rico-Juan and Paloma {Taltavull de La Paz};Expert Systems with Applications;2021;El Compendex;114590;171;Two sets of modelling tools are used to evaluate the precision of housing-price forecasts: machine learning and hedonic regression. Evidences on the prediction capacity of a range of methods points to the superiority of the random forest as it can calculate real-estate values with an error of less than 2%. This method also ranks the attributes that are most relevant to determining housing prices. Hedonic regression models are less precise but more robust as they can identify the housing attributes that most affect the level of housing prices. This empirical exercise adds new knowledge to the literature as it investigates the capacity of the random forest to identify the three dimensions of non-linearity which, from an economic theoretical point of view, would identify the reactions of different market agents. The intention of the robustness test is to check for these non-linear relationships using hedonic regression. The quantile tools also highlight non-linearities, depending on the price levels. The results show that a combination of techniques would add information on the unobservable (non-linear) relationships between housing prices and housing attributes on the real-estate market.;;https://doi.org/10.1016/j.eswa.2021.114590;https://www.sciencedirect.com/science/article/pii/S0957417421000312;;;Forecasting housing prices, Hedonic tools, Machine Learning, Models’ explainability;;0957-4174;;;
127;S;Artificial neural networks and deep learning in urban geography: A systematic review and meta-analysis;George Grekousis;Computers, Environment and Urban Systems;2019;El Compendex;244-256;74;Artificial neural networks (ANNs) and their latest advancement in deep learning are blooming in computer science. Geography has integrated these artificial intelligence techniques, but not with the same enthusiasm. The main reason for hesitation is that ANNs are still confronted as complex and black boxes. However, ANNs might be more solid methods than conventional approaches when dealing with complex geographical problems. This study considers the great potential of ANNs for research in urban geography. First, using the PRISMA protocol, it provides a statistical review of 140 papers on studies that employed ANNs in urban geography between 1997 and 2016. Second, it performs a quantitative meta-analysis using non-parametric bootstrapping. 45 (of the 140) papers were assessed regarding ANNs' overall accuracy (OA) achieved when used for urban growth prediction or urban land-use classification. Third, a new guideline for reporting ANNs is proposed. Statistical review indicated that ANNs performed better in 75.7% of case studies compared to conventional methods. Meta-analysis found that on bootstrapped averages, the median OA achieved when using, ANNs was higher than the median OA achieved by other techniques by 2.3% (p?<?.001). ANNs also performed better when used for classification compared to prediction. Analysis also identified inadequate presentation of ANNs and related results when used in urban studies. For this reason, a new guideline for reporting ANNs is suggested in this work to ensure consistency and easier dissemination of individual lessons learned. These findings aim to motivate further studies on ANNs and deep learning in urban geography.;;https://doi.org/10.1016/j.compenvurbsys.2018.10.00;https://www.sciencedirect.com/science/article/pii/S0198971518302928;;;Artificial Neural Networks, Deep Learning, Urban Geography, Meta-analysis, Trends, Guidelines on Reporting results;;0198-9715;;;
128;S;Towards Data-Driven Simulation Modeling for Mobile Agent-Based Systems;Keller, Nicholas and Hu, Xiaolin;ACM Trans. Model. Comput. Simul.;2019;ACM Digital Library;;29;"Simulation models are widely used to study complex systems. Current simulation models are generally handcrafted using expert knowledge (knowledge-driven); however, this process is slow and introduces modeler bias. This article presents an approach towards data-driven simulation modeling by developing a framework that discovers simulation models in an automated way for mobile agent-based applications. The framework is comprised of three components: (1) a model space specification, (2) a search method (genetic algorithm), and (3) framework measurement metrics. The model space specification provides a formal specification for the general model structure from which various models can be generated. The search method is used to efficiently search the model space for candidate models that exhibit desired behavior patterns. The five framework measurement metrics: flexibility, comprehensibility, controllability, composability, and robustness, are developed to evaluate the overall framework. The results demonstrate that it is possible to discover a variety of interesting models using the framework.";;10.1145/3289229;https://doi.org/10.1145/3289229;;;agent-based, Framework, mobile agent;Association for Computing Machinery;1049-3301;;;
129;S;Housing Demand Estimation Based on Express Delivery Data;Li, Qingyang and Yu, Zhiwen and Guo, Bin and Xu, Huang and Lu, Xinjiang;ACM Trans. Knowl. Discov. Data;2019;ACM Digital Library;;13;Housing demand estimation is an important topic in the field of economic research. It is beneficial and helpful for various applications including real estate market regulation and urban planning, and therefore is crucial for both real estate investors and government administrators. Meanwhile, given the rapid development of the express industry, abundant useful information is embedded in express delivery records, which is helpful for researchers in profiling urban life patterns. The express delivery behaviors of the residents in a residential community can reflect the housing demand to some extent. Although housing demand has been analyzed in previous studies, its estimation has not been very good, and the subject remains under explored. To this end, in this article, we propose a systematic housing demand estimation method based on express delivery data. First, the express delivery records are aggregated on the community scale with the use of clustering methods, and the missing values in the records are completed. Then, various features are extracted from a less sparse dataset considering both the probability of residential mobility and the attractiveness of residential communities. In addition, given that the correlations between different districts can influence the performances of the inference model, the commonalities and differences of different districts are considered. After obtaining the features and correlations between different districts being obtained, the housing demand is estimated by using a multi-task learning method based on neural networks. The experimental results for real-world data show that the proposed model is effective at estimating the housing demand at the residential community level.;;10.1145/3332522;https://doi.org/10.1145/3332522;;;express delivery data, Housing demand, multi-task learning;Association for Computing Machinery;1556-4681;;;
130;S;Dynamic Language Models for Continuously Evolving Content;Amba Hombaiah, Spurthi and Chen, Tao and Zhang, Mingyang and Bendersky, Michael and Najork, Marc;;2021;ACM Digital Library;2514–2524;;The content on the web is in a constant state of flux. New entities,issues, and ideas continuously emerge, while the semantics of the existing conversation topics gradually shift. In recent years, pre-trained language models like BERT greatly improved the state-of-the-art for a large spectrum of content understanding tasks.Therefore, in this paper, we aim to study how these language models can be adapted to better handle continuously evolving web content.In our study, we first analyze the evolution of 2013 - 2019 Twitter data, and unequivocally confirm that a BERT model trained on past tweets would heavily deteriorate when directly applied to data from later years. Then, we investigate two possible sources of the deterioration: the semantic shift of existing tokens and the sub-optimal or failed understanding of new tokens. To this end, we both explore two different vocabulary composition methods, as well as propose three sampling methods which help in efficient incremental training for BERT-like models. Compared to a new model trained from scratch offline, our incremental training (a) reduces the training costs, (b) achieves better performance on evolving content, and (c)is suitable for online deployment. The superiority of our methods is validated using two downstream tasks. We demonstrate significant improvements when incrementally evolving the model from a particular base year, on the task of Country Hashtag Prediction, as well as on the OffensEval 2019 task.;;10.1145/3447548.3467162;https://doi.org/10.1145/3447548.3467162;;;hard example mining, dynamic vocabulary, incremental learning, active learning, language modeling, vocabulary composition;Association for Computing Machinery;;;;
131;S;DiAd: Domain Adaptation for Learning at Scale;Zeng, Ziheng and Chaturvedi, Snigdha and Bhat, Suma and Roth, Dan;;2019;ACM Digital Library;185–194;;Massive online courses occupy an important place in the educational landscape of today. We study an approach to scale predictive analytic models derived from online course discussion fora--specifically that of confusion detection--onto other courses. The primary challenge here is the lack of labeled examples in a new course and this calls for unsupervised domain adaptation (DA). As a first step in exploring DA in the education domain, we propose a simple algorithm, DiAd, which adapts a classifier trained on a course with labeled data by selectively choosing instances from a new course (with no labeled data) that are most dissimilar to the course with labeled data and on which the classifier is very confident of classification. Our algorithm is empirically validated on the confusion detection task across multiple online courses. We find that DiAd outperforms other methods on the target domain, while showing a comparable performance to a popular method that uses labeled data from the target domain.;;10.1145/3303772.3303810;https://doi.org/10.1145/3303772.3303810;;;Confusion Detection, Domain Adaptation, Learning at Scale;Association for Computing Machinery;;;;
132;S;Modeling Real Estate Dynamics Using Temporal Encoding;Jiang, Chen and Li, Jingjing and Wang, Wenlu and Ku, Wei-Shinn;;2021;ACM Digital Library;516–525;;Deep learning has assisted modern life in various ways. One example is that accurate economic prediction helps people better allocate and distribute their resources. In the U.S., home prices have been accelerating during the COVID-19 pandemic and climbed 13.3% in March 2021 from the previous year. Real estate market prediction is critical for home buyers and investors to make wise decisions. In some circumstances, accurate predictions on home prices are more important than usual in helping decision-makers to reduce financial mistakes.In this paper, we introduce a large-scale real estate-related dataset for the value prediction task. It consists of numerical real estate price history data from Zillow1 and survey data from Census Bureau public dataset. Our goal is to utilize data from different levels to model the real-estate dynamics with temporal and non-temporal data. We propose to embed sequential temporal features using a transformer and combine them with non-temporal features for subsequent prediction tasks, and evaluate using a different number of classes L ? {2, 3, 4, 5}. As an example, when L = 2, we have achieved 93.5% accuracy with our proposed model, and when L = 3, our proposed model has achieved 90.1% prediction accuracy. The results suggest that the proposed model overall outperforms all the baseline models.;;10.1145/3474717.3484254;https://doi.org/10.1145/3474717.3484254;;;Transformer, Deep Learning, Spatial-temporal Data;Association for Computing Machinery;;;;
133;S;Prediction of Office Building Rental upon Spatiotemporal Data;Wang, Zhihong and Cao, Buyang;;2019;ACM Digital Library;168–174;;This paper presents a study on effectively predicting office building rentals based on the surrounding spatiotemporal data. During the planning, development, and construction stages of an office building, the stakeholders of the building may have one question to be answered, i.e., what the potential value of the office building is. The potential value of office buildings may be hard to be measured directly, however, it can be reflected in the rental after the office is put into operation. An accurate prediction of the office building rental will provide the solid base for the corresponding stakeholders to make business decisions. The rental of office buildings is affected by many factors, such as its location, floors, number of parking spots, the convenience of transportation, as well as the activities of the surrounding business. To support the rental prediction, we collect the datasets from different data sources in Shanghai. The linear regression, the decision tree, and the random forest models are employed in the computational experiments to predict the office building rentals and the most suitable prediction methodology for predicting the office building rental is suggested upon the experiments.;;10.1145/3352411.3352438;https://doi.org/10.1145/3352411.3352438;;;Prediction, Regression model, Machine learning, Parameter optimization, Commercial estate;Association for Computing Machinery;;;;
134;S;"Combining Domain Knowledge &amp; Machine Learning: Making Predictions Using Boosting Techniques";Cinar, Utku Kubilay;;2019;ACM Digital Library;9–13;;The latest hit on technology is the information and telecommunication novelties. Internet and big data are important source of information in order to understand this vast majority of the upcoming knowledge. Websites are progressively expanding and making it available to everyone who has access. Modern economic systems are built on data or knowledge. Thus, tech companies gather huge data and exercise their powers to digitalize the information to capture and utilize the knowledge within their reach. Information management enables firms to improve customer satisfaction, increase revenue, understand customer behavior, mitigate risk assessment, making a multidisciplinary approach. Another approach is to be able to identify business strategies. Information management researches (using machine learning algorithm) can help the field to discover what is significant on a customer behavior and reduce costs to its clients. Over the recent years, information management and machine learning algorithms are getting more and more close and on topic. Since, information management and machine learning intensely concerns with domain knowledge. Artificial Intelligence allows the machines to accumulate knowledge and adapts it. Information management and machine learning are affected by several factors such as business strategies, customer behavior, effectively using knowledge. Therefore, pulling only a single topic will not be enough to capture meaningful information from a huge chunk. Machine learning, and information systems also have the potential to help organizations in financial aspects. XG-Boost is one of the algorithms under the Decision-Trees equipped with boosting techniques similar to Microsoft's Light GBM algorithm. In recent years, XG-Boost algorithm has gained huge popularity due to its easy to use, speed, and performance. The aim of this paper is to show the use of the data in order to predict house prices XG-Boost algorithm and Neural Network model. The main goal here is to estimate the house prices using domain knowledge and machine learning algorithms. RMSE criteria was preferred. This paper suggests a generic way to gather knowledge on a very specific domain. Following the achieved result, the house price was estimated by processing the domain info through the machine learning algorithm here presented.;;10.1145/3369114.3369125;https://doi.org/10.1145/3369114.3369125;;;AI solutions, information, machine learning, capturing, xgboost, domain knowledge;Association for Computing Machinery;;;;
135;S;Spatial Prediction of Housing Prices in Beijing Using Machine Learning Algorithms;Yan, Ziyue and Zong, Lu;;2020;ACM Digital Library;64–71;;The real estate industry places key influence on almost every aspect of social economy given its great financing capacity and prolonged upstream and downstream industry chain. Therefore, predicting housing prices is regarded as an emerging topic in the recent decades. Hedonic Regression and Machine Learning Algorithms are two main methods in this field. This study aims to explore the important explanatory features and determine an accurate mechanism to implement spatial prediction of housing prices in Beijing by incorporating a list of machine learning techniques, including XGBoost, linear regression, Random Forest Regression, Ridge and Lasso Model, bagging and boosting, based on the housing price and features data in Beijing, China. Our result shows that compared to traditional hedonic method, machine learning methods demonstrate significant improvements on the accuracy of estimation despite that they are more time-costly. Moreover, it is found that XGBoost is the most accurate model in explaining and prediciting the spatial dynamics of housing prices in Beijing.;;10.1145/3409501.3409543;https://doi.org/10.1145/3409501.3409543;;;Housing Price, Spatial Modeling, Machine Learning Algorithms, Prediction;Association for Computing Machinery;;;;
136;S;House Rent Prediction Based on Joint Model;Zhang, Kun and Shen, LingCong and Liu, Ningning;;2019;ACM Digital Library;507–511;;With the development of the house leasing market, the house rents of several large cities in China have experienced rapid growth due to the increasing demand. In this paper, we focus on investigating various machine learning approaches to predict the house rent. Firstly, we not only have investigated different rent-related features including community condition, location, traffic and house condition, but also have employed various prediction models including XGBoost, LightGBM and CatBoost algorithms. Based on these, we proposed a joint model, which is a combination of above three models by linear weighting learned from least square method. Our best model ranks in top3% in the public Data Castle competition, which proves the joint model can effectively improve the accuracy and stability of the rent prediction compared to other prediction models.;;10.1145/3373509.3373578;https://doi.org/10.1145/3373509.3373578;;;XGBoost, LightGBM, Joint Model, House Rent, CatBoost, Prediction;Association for Computing Machinery;;;;
137;S;Simulation Framework for Self-Evolving Agent-Based Models: A Case Study of Housing Market Model;Bae, Jang Won and Paik, Euihyun and Kang, Dong-oh and Jung, Junyoung and Lee, Chun-Hee;;2018;ACM Digital Library;1120–1131;;Agent-based modeling and simulation (ABMS) has been applied to various domain problems. ABM consists of multiple agents and environments and focuses on their interactions. While such characteristics lead to its current popularity, they partially makes hard for the model calibration. Model calibration is generally performed by tuning model parameters, but in the ABM case, its interaction structure should be considered as well due to its huge influences to the results. To resolve this problem, this paper suggests a self-evolving ABMS framework. During the self-evolving process, ABM structure as well as parameters are explored and exploited for the model calibration. In particular, we adopt reconfigurable modeling in the proposed simulation framework, which is derived from Discrete Event System Specification (DEVS) formalism. This paper introduces a housing ABM, and the case study using this model shows that the accuracy of the model prediction was significantly increased through the self-evolving process.;;;;;;;IEEE Press;;;;
138;S;Prediction and Analysis of Chengdu Housing Rent Based on XGBoost Algorithm;Ming, Yue and Zhang, Jie and Qi, Jiaming and Liao, Tian and Wang, Maolin and Zhang, Lingli;;2020;ACM Digital Library;1–5;;Based on the online housing platform, this paper grabs 33224 pieces of data of Chengdu housing rental for visual analysis and prediction. Firstly, according to the importance of the characteristic attributes of the rental data, the characteristic factors such as area, housing area, orientation, rent collection mode, transportation, structure, etc. are selected. Through the data visualization method, it is found that Chengdu tenants have a greater demand for joint rental and small area apartment types. Then, 12 important features are predicted and fitted by RandomForestRegressor, XGBoost and LightGBM, and the best prediction accuracy is 0.85 on XGBoost model through parameter adjustment. Compared with RandomForestRegressor and LightGBM models, XGBoost model is more excellent in the application of this data set, and the prediction results have certain reference value for housing rental prices.;;10.1145/3422713.3422720;https://doi.org/10.1145/3422713.3422720;;;LightGBM, XGBoost, Housing rent forecast, Visual analysis;Association for Computing Machinery;;;;
139;S;Data Assimilation Technique for Social Agent-Based Simulation by Using Reinforcement Learning;Kang, Dong-oh and Bae, Jang Won and Lee, Chunhee and Jung, Joon-Young and Paik, Euihyun;;2018;ACM Digital Library;220–221;;This paper presents a data assimilation technique for social agent-based simulation to fit real world data automatically by a reinforcement learning method. We used the hidden Markov model in order to estimate the states of the system during the reinforcement learning. The proposed method can improve simulation models of the social agent-based simulation incrementally when new real data are available without total optimization. In order to show the feasibility, we applied the proposed method to a housing market problem with real Korean housing market data.;;;;;;agent-based, data assimilation, hidden Markov model, reinforcement learning, social simulation;IEEE Press;;;;
